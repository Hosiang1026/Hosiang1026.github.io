<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="Access-Control-Allow-Origin" content="*"><script type="text/javascript">var start_time=(new Date).getTime()</script><meta http-equiv="Cache-Control" content="no-cache"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="viewport" content="initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="google-site-verification" content="9Wt3lmnrT2bfjaHla5s16adhvcQcBHO7PtNf97n5Od0"><meta name="baidu-site-verification" content="RYlYHsgO7Y"><meta name="sogou_site_verification" content="MSmrTj7lHV"><meta name="shenma-site-verification" content="e4428ccce0f22fad61c3716193bf4bd7_1571416388"><meta name="baidu_union_verify" content="584bb6b4bd24108df082b6d20c7aa9be"><title>推荐系列-案例分享 - ElasticDL-同时提升集群利用率和研发效率的分布式深度学习框架 | 狂欢马克思</title><meta name="keywords" content="分享技术经验与交流"><meta name="description" content="&amp;emsp;&amp;emsp;本文同步发布在 TensorFlow 微信���众号、知乎 SQLFlow 专栏，获得作者授权在开源中国发布，原作者为蚂蚁集团 齐俊、王益 ElasticDL 是一个基于 TensorFlow 2.x 和 Kubernetes 的开源的分布式…"><meta property="og:type" content="article"><meta property="og:title" content="推荐系列-案例分享 - ElasticDL-同时提升集群利用率和研发效率的分布式深度学习框架"><meta property="og:url" content="https://www.hosiang.cn/2b4e32ca/index.html"><meta property="og:site_name" content="狂欢马克思"><meta property="og:description" content="&amp;emsp;&amp;emsp;本文同步发布在 TensorFlow 微信���众号、知乎 SQLFlow 专栏，获得作者授权在开源中国发布，原作者为蚂蚁集团 齐俊、王益 ElasticDL 是一个基于 TensorFlow 2.x 和 Kubernetes 的开源的分布式…"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2021-04-13T23:54:42.000Z"><meta property="article:modified_time" content="2022-06-22T09:43:14.417Z"><meta property="article:author" content="Howe Hsiang"><meta property="article:tag" content="Popular"><meta name="twitter:card" content="summary"><link rel="icon" href="/images/favicon.ico"><link href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"><link href="https://cdn.bootcss.com/font-awesome-animation/0.1.0/font-awesome-animation.min.css" rel="stylesheet"><link rel="stylesheet" href="/css/style.css"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?3cd8fa109426bf3f10bd5c362175bace";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta name="generator" content="Hexo 6.2.0"></head><script src="/js/jquery.min.js"></script><script src="/js/pace.min.js"></script><script src="/js/crypto-js.js"></script><script src="/js/cookie.js"></script><script src="/js/calendar.js"></script><script src="/js/festival.js"></script><script>getFestival()</script><body><script>window.onload=function(){document.getElementById("TimeShow").innerHTML="本站耗时 "+((new Date).getTime()-start_time)/1e3+" 秒 "}</script><div id="container"><header id="header"><div id="banner"></div><div id="header-outer"><div id="header-menu" class="header-menu-pos animated"><div class="header-menu-container"><a href="/" class="left"><span class="site-title">狂欢马克思</span></a><nav id="header-menu-nav" class="right"><a href="/" rel="external nofollow"><i class="fa fa-home"></i> <span>主页</span> </a><a href="/archives" rel="external nofollow"><i class="fa fa-archive"></i> <span>归档</span> </a><a href="/gitbook" rel="external nofollow"><i class="fa fa-columns"></i> <span>笔记</span> </a><a href="/music" rel="external nofollow"><i class="fa fa-music"></i> <span>音乐</span> </a><a href="/photo" rel="external nofollow"><i class="fa fa-picture-o"></i> <span>相册</span> </a><a href="/love" rel="external nofollow"><i class="fa fa-heart"></i> <span>恋爱</span> </a><a href="/collection" rel="external nofollow"><i class="fa fa-envira"></i> <span>收藏</span> </a><a href="/about" rel="external nofollow"><i class="fa fa-user"></i> <span>关于</span></a></nav><a class="mobile-header-menu-button"><i class="fa fa-bars"></i></a></div></div><div id="header-row"><div id="logo"><a href="/"><img src="/../images/logo.png" alt="logo"></a></div><div class="header-info"><div id="header-title"><h2>狂欢马克思</h2></div><div id="header-description"><h3>专注Web开发</h3></div></div><nav class="header-nav"><div class="social"><a title="Github" target="_blank" href="//github.com/Hosiang1026" rel="external nofollow"><i class="fa fa-github fa-2x"></i></a> <a title="QQ" target="_blank" href="//wpa.qq.com/msgrd?v=3&uin=641904695&site=qq&menu=yes" rel="external nofollow"><i class="fa fa-qq fa-2x"></i></a> <a title="Weibo" target="_blank" href="//www.weibo.com/haoxiang969" rel="external nofollow"><i class="fa fa-weibo fa-2x"></i></a></div></nav></div><script type="text/javascript" src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script><div id="noticeId" class="show" style="background:rgb(244,247,247,.3)"><marquee id="noticeMar" behavior="scoll" class="notice" direction="left" onmouseover="this.stop()" onmouseout="this.start()"></marquee></div><script type="text/javascript">function browserRedirect(){var i=navigator.userAgent.toLowerCase(),n="ipad"==i.match(/ipad/i),e="iphone os"==i.match(/iphone os/i),o="midp"==i.match(/midp/i),a="rv:1.2.3.4"==i.match(/rv:1.2.3.4/i),s="ucweb"==i.match(/ucweb/i),t="android"==i.match(/android/i),r="windows ce"==i.match(/windows ce/i),c="windows mobile"==i.match(/windows mobile/i),d="",m=randomColor(),d=n||e||o||a||s||t||r||c?($("#noticeId").css({"line-height":"1.6em"}),"<font style='color:"+m+"' face='新华宋体'  size='2'>官宣：<span id='msg'></span><span id='timer'></span><span id='jinrishici-sentence'></span></font> "):($("#noticeId").css({"line-height":"3.6em","margin-top":"20px"}),"<font style='color:"+m+"' face='新华宋体'  size='6'>官宣：<span id='weekend'></span><span id='msg'></span><span id='timer'></span><span id='jinrishici-sentence'></span></font> ");$("#noticeMar").html(d)}function randomColor(){for(var i="0,1,2,3,4,5,6,7,8,9,a,b,c,d,e,f".split(","),n="#",e=0;e<6;e++)n+=i[Math.floor(16*Math.random())];return n}$(function(){browserRedirect()})</script></div></header><script>console.log=function(){}</script><div class="outer"><section id="main" class="body-wrap"><article id="post-案例分享 - ElasticDL-同时提升集群利用率和研发效率的分布式深度学习框架" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 class="post-title" itemprop="name">推荐系列-案例分享 - ElasticDL-同时提升集群利用率和研发效率的分布式深度学习框架</h1><div class="post-title-bar"><ul><li><i class="fa fa-book"></i> <a href="/categories/热门文章/">热门文章</a></li><li><i class="fa fa-calendar"></i> 2021-04-14</li><li><i class="fa fa-eye"></i> <span id="busuanzi_value_page_pv"></span></li><li><span class="post-count">字数统计: 5.5k字</span></li><li><span class="post-count">阅读时长: 20分钟</span></li></ul></div></header><div class="article-entry post-content" itemprop="articleBody"><p>&amp;emsp;&amp;emsp;本文同步发布在 TensorFlow 微信���众号、知乎 SQLFlow 专栏，获得作者授权在开源中国发布，原作者为蚂蚁集团 齐俊、王益 ElasticDL 是一个基于 TensorFlow 2.x 和 Kubernetes 的开源的分布式…</p><span id="more"></span><p>ElasticDL 是一个基于 TensorFlow 2.x 和 Kubernetes 的开源的分布式深度学习编程框架。2019 年秋天的 Google Developer Day 活动中来自蚂蚁金服的 ElasticDL 团队展示了 ElasticDL 的第一个开源版本。本文更新这大半年来 ElasticDL 项目的进展，尤其是性能优化和业务落地。<br>相关报道资料：</p><p>ElasticDL: 基于 TensorFlow 2.0 和 Kubernetes 的弹性分布式深度学习 - Google Developer Days 2019<br>ElasticDL GitHub repo</p><p>ElasticDL 的首要设计意图是简化分布式编程。它允许用户只提供用 TensorFlow 2.0 API 描述的模型，而不需要用户写分布式训练过程代码。用户的模型定义只要能在本地调通，即可在分布式环境下用大规模数据训练模型，从而提升研发效率。<br>同时，ElasticDL 提供的弹性调度的能力在实践中可以让集群的利用高达 90%。当集群资源不足时，一个训练作业里的进程减少；当其他作业结束释放资源后，进程数量随之增加。这样的做法比 TensorFlow Distribution Strategy 专注容错（进程减少的情况下作业不失败，但不会增加进程数量）更进一步。并且，因为 ElasticDL 作业容忍变化的 worker 数量，所以每个作业的启动都不必等待集群有足够的资源，而是可以见缝插针的尽早开始训练，从而缩短等待作业启动的时间，让研发人员可以尽快看到第一个迭代的结果，万一分布式训练有问题，也能尽早发现，从而进一步提升了研发效率。</p><h3 id="简化分布式深度学习编程"><a href="#简化分布式深度学习编程" class="headerlink" title="简化分布式深度学习编程"></a>简化分布式深度学习编程</h3><p>为了从海量数据中学习规律，我们需要编写分布式深度学习程序来完成训练任务。这在工业场景中尤为常见。<br>可分布式深度学习程序的编写很难 —— 编程者既要了解深度学习，也要了解分布式系统开发。在一个分布式深度学习系统中，需要启���和监控若干个 workers。因为既要拆分训练数据给 workers，还要综合各个 worker 算出的 gradients 来更新模型，所以涉及通信 (Communication) 和 同步 (Synchronization)。此外，当 worker 数目很多时，作业在执行过程中有 worker 挂掉的概率也会变得很大。如果一个 worker 挂掉，则整个作业重启或者恢复到最近的 checkpoint (Fault Recovery)，那么重启之后可能又会有 worker 挂掉导致重启，于是作业不断陷入重启和恢复，永远也无法完成。这进一步要求编程者具备设计容错 (Fault Tolerance) 系统的能力。其实不仅分布式深度学习，其他分布式机器学习 程序、分布式离线和在线数据处理程序等各种分布式程序的写作，都对编程者有类似上述要求。<br>一个常见的解决思路是为特定类型的作业提供分布式编程框架，让用户只需要完形填空一样补上业务逻辑，而分布式计算（包括通信、同步、和容错）都由框架的代码来完成。一个典型的例子是离线数据处理程序用 MapReduce 框架来写。不管是 Google MapReduce 还是 Hadoop MapReduce，用户基本都只需填写 map 和 reduce 两个函数的实现即可。类似的，在线数据流系统基于 Storm 和 Flink 来写，用户只需提供 bolts 和 nuts 这样的业务逻辑定义。<br>在 ElasticDL 之前，蚂蚁金服的同事们使用过多种框架和类似框架的高层 API。这些方案 大都基于 TensorFlow 和 Kubernetes。</p><p>TensorFlow Estimator 作为构建在 TensorFlow 之上的一层 API，允许用户只需定义模 型，而训练过程封装在一个函数调用里。利用 Kubeflow 提供的 TF operator，我们可以将该训练过程以分布式作业的方式启动在Kubernetes 上。这个方案的局限是：它仅支持 TensorFlow 的 graph mode，不支持 eager execution；而 eager execution 可以 大幅简化调试，尤其方便跟踪网络各层输出。<br>Keras API 支持 TensorFlow 2.x 和 eager execution。目前 TensorFlow 2.x Keras API 还暂不支持 ParameterServer 分布式策略，对 AllReduce 分布式策略提供了实验性的支持。<br>Horovod 对用户代码有侵入性，用户除了必须熟悉 TensorFlow API 之外，还需学习 Horovod API。</p><p>以上三个方案的共同局限是，虽然具备一定的容错能力，不过不支持弹性调度。而且它们都依赖部署 Kubernetes operator，了解 Kubernetes 对 AI 专家来说颇有挑战。</p><p>针对这些局限，我们设计和开发了 ElasticDL 分布式计算框架。用户定义可以用 TensorFlow 2.x 的 Keras API 来定义模型。并且，分布式执行不要求 Kubernetes 集群有 任何特殊配置，而是利用每个作业里的 master 进程来协调训练数据分配、通信、同步、和容错 —— 这也是 ElasticDL 除了容错，支持弹性调度的原因。</p><h3 id="基于-ElasticDL-框架的编程"><a href="#基于-ElasticDL-框架的编程" class="headerlink" title="基于 ElasticDL 框架的编程"></a>基于 ElasticDL 框架的编程</h3><p>就像 MapReduce 框架中只需要用户完形填空两个函数：map 和 reduce，ElasticDL需要用户填写 forward、loss、optimizer、feed 函数。其中 forward 定义深度学习的前向计算过程 (Forward Pass)，ElasticDL 会调用 TensorFlow eager execution 的 GradientTape 机制来自动推导对应的后向计算过程 (Backward Pass)；loss 函数返回模 型训练时使用的损失函数；optimizer 函数返回模型训练时使用的优化器；feed 定制化训练数据到 TensorFlow 模型输入 (tensors) 的转换过程。<br>所有这些函数的编程只需要了解 TensorFlow API，不需要对分布式训练有任何背景知识。写完之后，用户可以在单机上用小数据做调试验证。如果通过，可以不做任何代码修改就提交到 Kubernetes 集群上做分布式的容错的大规模训练。<br>不同于 Kubeflow&#x2F;TF-operator 给每个集群部署一个 Kubernetes Operator 的方式， ElasticDL 为每个作业引入一个 master 进程。通过调用 Kubernetes API，master 进程了解集群情况；同时，作为作业的一部分，master 还了解深度学习作业的特点 —— 包括利用 Python inspection 机制了解上述各个函数的特点，其中调用的 API 函数等。所以， master 有非常充分的信息来做更优的调度。比如 master 可以请 Kubernetes 把两个 worker 启动在同一台物理机上，共用一个 GPU —— 当一个 worker 读数据的时候，请另外一个 worker 来做计算，从而始终保持较高的 GPU 利用率。</p><h3 id="一个例子"><a href="#一个例子" class="headerlink" title="一个例子"></a>一个例子</h3><p>我们用一个 MNIST 手写数字识别的例子来说明。</p><pre><code class="java"> def forward():
   inputs = tf.keras.Input(shape=(28, 28), name=&quot;image&quot;)
   x = tf.keras.layers.Reshape((28, 28, 1))(inputs)
   x = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=&quot;relu&quot;)(x)
   x = tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=&quot;relu&quot;)(x)
   x = tf.keras.layers.BatchNormalization()(x)
   x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)
   x = tf.keras.layers.Dropout(0.25)(x)
   x = tf.keras.layers.Flatten()(x)
   outputs = tf.keras.layers.Dense(10)(x)
   return tf.keras.Model(inputs=inputs, outputs=outputs, name=&quot;mnist_model&quot;)
</code></pre><p>除了模型定义之外，用户还需要指定 feed, loss，optimizer 函数。</p><pre><code class="java"> def loss(labels, predictions):
   labels = tf.reshape(labels, [-1])
   return tf.reduce_mean(
       input_tensor=tf.nn.sparse_softmax_cross_entropy_with_logits(
           logits=predictions, labels=labels
       )
   )

def optimizer(lr=0.1):
   return tf.optimizers.SGD(lr)

def feed(dataset, mode, _):
   def _parse_data(record):
       if mode == Mode.PREDICTION:
           feature_description = &#123;
               &quot;image&quot;: tf.io.FixedLenFeature([28, 28], tf.float32)
           &#125;
       else:
           feature_description = &#123;
               &quot;image&quot;: tf.io.FixedLenFeature([28, 28], tf.float32),
               &quot;label&quot;: tf.io.FixedLenFeature([1], tf.int64),
           &#125;
       r = tf.io.parse_single_example(record, feature_description)
       features = &#123;
           &quot;image&quot;: tf.math.divide(tf.cast(r[&quot;image&quot;], tf.float32), 255.0)
       &#125;
       if mode == Mode.PREDICTION:
           return features
       else:
           return features, tf.cast(r[&quot;label&quot;], tf.int32)

   dataset = dataset.map(_parse_data)

   if mode == Mode.TRAINING:
       dataset = dataset.shuffle(buffer_size=1024)
   return dataset
</code></pre><p>上述每个函数都很容易做单独测试 (unit test)。而且，利用 TensorFlow 2.x eager execution，上述函数很容易 log 每一层的输出。基于个特点，ElasticDL worker 在调用 forward 函数的时候，可以打印中间结果，便于调试和复现问题。</p><h3 id="ElasticDL-的弹性训练过程"><a href="#ElasticDL-的弹性训练过程" class="headerlink" title="ElasticDL 的弹性训练过程"></a>ElasticDL 的弹性训练过程</h3><p>给定上述模型定义，ElasticDL 的 master 进程按照 asynchronous 或者 synchronous SGD 方法，协调 workers 来做训练。当使用 asynchronous SGD 方法时，master 会启动一个高性能的 parameter server，供各个 workers 使用。当使用 synchronous SGD 时，ElasticDL 使用和才云科技合作研发的一个 Kubernetes-native 的 fault-tolerable AllReduce 实现 FTlib。</p><h4 id="Master-负责动态数据划分"><a href="#Master-负责动态数据划分" class="headerlink" title="Master 负责动态数据划分"></a>Master 负责动态数据划分</h4><p>弹性训练过程的一个容易被忽略的前提是动态数据划分 (Dynamic data partitioning)。在用 MPI 写分布式程序的时候，因为作业中进程数量是恒定的，所以经常采用静态数据 划分的做法 —— 在训练之前把训练数据预先分成 N 个文件，对应作业中的 N 个 worker 进程。这个做法在弹性调度的时候就失效了 —— 因为弹性调度时，作业中的进程数量是可变的。为此，需要实现动态数据划分。<br>ElasticDL 的动态数据划分是基于索引的。ElasticDL 要求训练数据是一个或者多个 RecordIO 格式的文件，或者是 MaxCompute 数据库系统中的表 (table)。这两种数据源都允许 master 进程在开始训练之前，在基本存储单元 (block) 间快速跳跃着扫描数据，把数据分成小段，称之为任务 (task)。每个 task 包括的内容如下：</p><p>文件名或者表名，<br>第一条记录相对于文件（或者表）开始处的偏移 (offset)，<br>这个 task 里的总记录数。</p><p>RecordIO <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/wangkuiyi/recordio">https://github.com/wangkuiyi/recordio</a><br>MaxCompute <a target="_blank" rel="external nofollow noopener noreferrer" href="https://www.alibabacloud.com/zh/product/maxcompute">https://www.alibabacloud.com/zh/product/maxcompute</a><br>扫描结果是很多 tasks，master 把这些 tasks 放进一个 TODO 队列里。这个队列不一定需要是 master 进程里的数据结构，可以是放在 etcd 里的 —— 因为 etcd 是不死的，所以 master 即使被高优先级作业抢占了，这个信息也不会丢失；可以通过在资源富余时重启 master 进程来恢复作业状态。</p><p>扫描和划分数据的同时，master 开始请 Kubernetes 启动 workers，总数不超过用户指定的数量 N（最大并发度）。每当一个 worker 启动起来了，master 会收到 Kubernetes 发来的通知；master 在一个 etcd 数据结构里记录“活着”的 workers。<br>扫描和划分数据结束之后，master 就依次从 TODO 队列里取出 task，通过 gRPC 发给某一个活着的 worker，同时 master 把这个 task 挪进 DOING 队列里。接收到 task 的 worker 负责打开文件（或者表），并且从指定的 offset 开始依次读取记录，并且更新本 地模型。根据用户选择的 asynchronous 或者 synchronous 算法，workers 会通过调用 parameter server 或者 AllReduce 来协调更新全局模型。<br>当一个 worker 处理完了接收到的 task，它通过 gRPC 返回一个表示成功的标记；master 就把这个 task 从 DOING 队列挪到 DONE 队列了。当所有 task 都从 TODO 挪进了 DONE， 则说明一个 epoch 完成了。<br>如果一个 worker 失败了（比如被更高优先级作业抢占了），则 master 的 gRPC call 会 timeout；此时，master 把对应的 task 从 DOING 队列挪回 TODO 队列了。下一次有 worker 完成 task 时，master 会把这个 task 再发出去。这里有一个细节：有的 task 可 能被某个 worker 使用了一部分，也因此影响到了模型更新；此时 worker 被抢占，那么这 部分已经被处理的数据会因为 task 的下一次分发，被重复使用。不过这个并不影响机器学 习训练要求数据统计一致性的假设。而且其他动态数据划分方法造成的数据复用情况可能更 严重。</p><h4 id="Woker-调用-TensorFlow-Eager-Execution"><a href="#Woker-调用-TensorFlow-Eager-Execution" class="headerlink" title="Woker 调用 TensorFlow Eager Execution"></a>Woker 调用 TensorFlow Eager Execution</h4><p>ElasticDL worker 接收到的一个 task 通常包括多个 minibatches。对于每个 task， worker 打开对应的文件或者表，随后做如下操作：</p><p>读取一个 mini-batch 的训练数据。<br>用本地模型 (local model) 作为参数调用用户定义的 forward 函数以计算 cost。如果 模型很大，则部��参数可能来自于 parameter server。<br>给定 cost，worker 利用 TensorFlow eager execution 的 GradientTape 机制，进行 backward 计算，得到梯度 (gradient)。<br>如果是 synchronous SGD，此时 worker 调用 AllReduce 实现 FTlib 来同步 gradients 并且更新模型。如果是 asynchronous SGD，worker 不定时的向 parameter server 上传 gradients，也不定时地从 parameter server 获取全局模型参数。</p><h4 id="高效训练的优化"><a href="#高效训练的优化" class="headerlink" title="高效训练的优化"></a>高效训练的优化</h4><p>相对于 2019 年秋季 ElasticDL 在 Google Developer Day 上亮相时的状态，最近几个月 ElasticDL 项目针对性能优化做了很多工作。当时 ElasticDL 使用 Redis 作为 parameter server。现在有了自己的用 Go 语言写的 parameter server。相对于 Redis， ElasticDL parameter server 可以做一些深度学习计算，从而减少 worker 和 parameter server 之 间通信的次数。<br>这个变化和其他优化工作一起让同样的训练作业，总体训练时间下降了约 13 倍。最近一个基于 DeepFM 模型的试验展示，用两个 parameter server 进程和四个 workers 进程来训练，10 个 epochs 的总体时间从 1350 秒（ElasticDL 的 2019年9月版本）下降到 106 秒（2020年2月版本）。这些优化策略包括：</p><p>在 parameter server 上惰性初始化 (lazy initialize) embedding vectors —— 在使用到 vector 的时候才初始化。<br>把一个 embedding table 拆分到多个 parameter server 进程里以均衡存储与通信负载。<br>worker 从 PS 请求 embedding vectors 时，先滤除重复的 embedding ID，只取回不同 ID 的 vectors，从而减少通信量。<br>worker 向 PS 发送梯度时，先把相同 ID 的梯度进行合并（调用 TensorFlow 的 embedding vector combination 函数），从而减少通信量。</p><h3 id="弹性调度提升集群利用率"><a href="#弹性调度提升集群利用率" class="headerlink" title="弹性调度提升集群利用率"></a>弹性调度提升集群利用率</h3><p>ElasticDL 实现的弹性调度和刚性调度 (Gang Scheduling) 是对应的。刚性调度的简洁不求甚解的描述是：一个作业里的 n 个进程，运行时如果有一个进程挂了（比如被更高优先级的作业抢占了资源），则整个作业挂掉。等资源足够再启动所有的 n 个进程了， 则可以重启（或者从最近的 checkpoint 恢复）。</p><p>Gang Scheduling <a target="_blank" rel="external nofollow noopener noreferrer" href="https://en.wikipedia.org/wiki/Gang_scheduling">https://en.wikipedia.org/wiki/Gang_scheduling</a> 上文提到的几种分布式运行 TensorFlow 作业的方式都使用了 Kubeflow 项目提供的 Kubernetes operators，支持在 Kubernetes 上分布式地运行 TensorFlow 作业。因为 TensorFlow runtime 目前支持一定程度的容错，所以作业执行过程中，如果有一些 workers 挂了，剩下的可以继续。不过不支持因为日后资源富余，恢复 workers 数量。XGBoost、MXNet 社区也习惯于复用 Kubeflow 的 Kubernetes operator。用 MPI 写的程序也可以用 Kubeflow 拉起。</p><p>而弹性调度 (Elastic Scheduling) 实现的是训练作业运行过程中，进程数量的变化不影响作业进行。具体的说，如果一个或者几个进程被高优先级的作业抢占，剩下的进程不受影响地继续进行。如果将来资源丰沛了，系统可以加几个进程，此时作业仍然不受影响地继续运行。<br>上文简述了 ElasticDL 实现弹性调度的机制，包括动态数据分配以及由 master 来启动、监控、和管理 workers，而不依赖 Kubernetes operator。本节展示三个 benchmark 试验，帮助大家直观地了解 ElasticDL 对集群利用率和研发效率的同时提升。</p><h3 id="实验一：多个-AI-训练作业并发"><a href="#实验一：多个-AI-训练作业并发" class="headerlink" title="实验一：多个 AI 训练作业并发"></a>实验一：多个 AI 训练作业并发</h3><p>考虑两个 AI 训练作业需要的资源总和略超过集群的情况：如果没有 elastic scheduling，则两个作业 顺序执行。第二个作业的发起人需要等很久 —— 用户体验不好。并且任何时刻只有一个作业在运行 —— 集群资源用不满。而如果有 elastic scheduling，则两个作业并发执行，虽然后启动的作业拿不到期待的全部资源，但是也马上就开始执行了 —— 用户体验好，而且因为作业并发集群被用满。<br>我们做了一个实验来验证上述好处。这个实验可以在 ASI 集群和开源 Kubernetes 集群上复现。实验结果如下图。</p><p>上图对应的实验里，我们用 gang scheduling 的方式提交了两个训练作业，每个作业都需要 13 个 CPU。而 Google Cloud 上租用的实验集群总 CPU 数是 24， 不足同时运行两个作业，所以依次运行它们。可以看到第一个作业在 395 秒时结束。随后集群花了一点时间调度，然后开始运行第二个作业，直到 795 秒时结束。<br>下图对应的实验里，我们用 ElasticDL 来执行同样的两个训练作业。第一个作业提交之后的 30 秒，我们提交了第二个作业。第二个作业马上就开始运行，用满了集群剩下的资源，而不需要等到第一个作业结束。在 395 秒时，第一个作业结束。随后，在 580 秒时，第二个作业也结束了。因为弹性调度，使得两个作业尽量同时运行，所以总结束时间比也上图要早。<br>总结：</p><p>用户等待作业启动时间几乎是 0。 这对于 AI 工作很重要，因为用户最关注的是第一个迭代尽快开始—— 如果第一个迭代失败了，很可能是用户程序的 bug。另外，深度学习模型往往需要手动调优，学习���、optimizer、activation 等配置如果不合理，往往在前几个迭代就能发现；因此第一个迭代能立刻开始，对模型调优的工作效率提高有很大帮助。<br>集群利用率高。 第二个实验 (elastic scheduling) 执行期间，有一段时间集群利用率是 100%；其他时间也不低于第一个实验 (gang scheduling)。<br>作业完成更快。 第二个试验里，两个作业用了约 580 秒；第一个实验里需要约 795 秒。</p><h3 id="实验二：AI-作业和在线服务混布"><a href="#实验二：AI-作业和在线服务混布" class="headerlink" title="实验二：AI 作业和在线服务混布"></a>实验二：AI 作业和在线服务混布</h3><p>运行各种在线服务的生产集群，通常需要留出余量资源，以应付突然增长的用户请求量。我们希望利用这些“余量”来做 AI 训练，从而提升集群利用率。下面实验验证：通过用较低优先级运行 ElasticDL 训练作业，在用户请求增加的时候，Kubernetes 自动扩容在线服务 (NGINX)；此时 ElasticDL 作业自动释放资源，配合在线服务的扩容。当流量高峰过去之后，Kubernetes 自动缩容 NGINX 服务，此时，ElasticDL 自动利用释放的资源。</p><p>图中紫色曲线是 NGINX 服务使用的 CPU 数量，随用户请求数量变化。绿色曲线是 ElasticDL 训练作业使用的 CPU 数量，随 NGINX 的资源需求自动变化。蓝色曲线是集群的总体资源利用率 —— 保持在 90% 以上。</p><h3 id="实验三：训练时更改-worker-数量不影响收敛性"><a href="#实验三：训练时更改-worker-数量不影响收敛性" class="headerlink" title="实验三：训练时更改 worker 数量不影响收敛性"></a>实验三：训练时更改 worker 数量不影响收敛性</h3><p>有用户担心训练过程中 worker 的数量发生变化，会导致不收敛。实际情况下从未发生这类问题。用 ElasticDL 和用 gang scheduling 分别训练 Wide &amp; Deep model 和 xDeepFM model， 收敛曲线如下： 可以看到，采用 gang scheduling 持续用 4 个或者 8 个 workers，和用 ElasticDL 并且 worker 数量在 4 到 8 之间变化，得到的收敛曲线很难分辨。差别在自然误差范围之内。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>蚂蚁金服从事的金融行业涉及支付、微贷、和保险等业务。和搜索、广告、推荐不同，金融业务的流程要复杂得多 —— 包括对用户信用的预判以及和其他金融机构的联动 —— 每一个用户请求对应很多处理步骤；而搜索、广告、推荐业务里针对每个用户请求的 AI 处理步骤少得多。行业特点导致蚂蚁金服要训练的模型的类型繁多，呈现更长尾的特点。也对工具提升研发效率提出了高要求。ElasticDL 正是针对这些特点设计的。<br>同时，对集群的利用率提升是各行各业都关注的。在很多公司和行业，AI 集群的利用率通常在 30% 以下。当通过全面实现弹性调度，把集群利用率提升到 90% 左右时，相当于空手套白狼地把集群规模扩大了为原来的三倍多。因此节省的硬件投资可能高达数千万甚至数亿元人民币。<br>ElasticDL 的设计和实现依托了 TensorFlow 2.x 提供的高效率的模型描述 API。也依赖了 TensorFlow eager execution 提供的 GradientTape 机制 —— 使得 ElasticDL 可以在不改变 TensorFlow runtime 的情况下，结合 Kubernetes 实现彻底的弹性调度（进程数可增也可减），从而实现了减少作业启动 的等待时间，提升集群利用率，和提升研发效率的效果。<br>目前 ElasticDL 在阿里系结合 PAI 平台在推广。PAI 平台提供的拖拽式编程模式进一步降低了端到端机器学习流程的研发门槛。希望接下来 ElasticDL 团队可以有更多结合业务实践的分享。</p><div class="post-copyright"><div class="content"><p>本文标题： 推荐系列-案例分享 - ElasticDL-同时提升集群利用率和研发效率的分布式深度学习框架</p><p>本文作者： OSChina</p><p>发布时间： 2021年04月14日 07:54</p><p>最后更新： 2022年06月22日 17:43</p><p>原始链接： <a class="post-url" href="/2b4e32ca/" title="推荐系列-案例分享 - ElasticDL-同时提升集群利用率和研发效率的分布式深度学习框架">https://www.hosiang.cn/2b4e32ca/</a></p><p>版权声明： 本文著作权归作者所有，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noopener noreferrer" target="_blank">CC BY-NC-SA 4.0</a>许可协议，转载请注明出处！</p><footer><a href="https://www.hosiang.cn"><img src="/../images/logo.png" alt="Howe Hsiang"> Howe Hsiang</a></footer></div></div><div class="page-reward"><a id="rewardBtn" href="javascript:;">赏</a></div><div id="reward" class="post-modal reward-lay"><a class="close" href="javascript:;" id="reward-close">×</a> <span class="reward-title"><i class="icon icon-quote-left"></i> 喜欢就赞赏一下呗！ <i class="icon icon-quote-right"></i></span><div class="reward-content"><div class="reward-code"><img id="rewardCode" src="/images/threepay_code.jpg" alt="打赏二维码"></div><div class="reward-select"></div></div></div></div><footer class="article-footer"><div class="post-share"><a href="javascript:" id="share-sub" class="post-share-fab"><i class="fa fa-share-alt" style="padding-top:11px!important"></i></a><div class="post-share-list" id="share-list"><ul class="share-icons"><li><a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://www.hosiang.cn/2b4e32ca/" data-title="Facebook" rel="external nofollow noopener noreferrer"><i class="fa fa-facebook" style="padding-top:9px!important"></i></a></li><li><a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《推荐系列-案例分享 - ElasticDL-同时提升集群利用率和研发效率的分布式深度学习框架》 — 狂欢马克思&url=https://www.hosiang.cn/2b4e32ca/&via=https://www.hosiang.cn" data-title="Twitter" rel="external nofollow noopener noreferrer"><i class="fa fa-twitter" style="padding-top:9px!important"></i></a></li><li><a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://www.hosiang.cn/2b4e32ca/" data-title="Google+" rel="external nofollow noopener noreferrer"><i class="fa fa-google-plus" style="padding-top:9px!important"></i></a></li><li><a class="qq share-sns" target="_blank" href="https://connect.qq.com/widget/shareqq/index.html?url=https://www.hosiang.cn/2b4e32ca/&title=《推荐系列-案例分享 - ElasticDL-同时提升集群利用率和研发效率的分布式深度学习框架》 — 狂欢马克思&source=&amp;emsp;&amp;emsp;本文同步发布在 TensorFlow 微信���众号、知乎 SQLFlow 专栏，获得作者授权在开源中国发布，原作..." data-title="QQ" rel="external nofollow noopener noreferrer"><i class="fa fa-qq" style="padding-top:9px!important"></i></a></li><li><a class="weixin share-sns" id="wxFab" href="javascript:" data-title="微信"><i class="fa fa-weixin" style="padding-top:9px!important"></i></a></li><li><a class="weibo share-sns" target="_blank" href="https://service.weibo.com/share/share.php?url=https://www.hosiang.cn/2b4e32ca/&title=《推荐系列-案例分享 - ElasticDL-同时提升集群利用率和研发效率的分布式深度学习框架》 — 狂欢马克思&pic=https://static.oschina.net/uploads/img/202007/20112159_N1KH.jpg" data-title="微博" rel="external nofollow noopener noreferrer"><i class="fa fa-weibo" style="padding-top:9px!important"></i></a></li></ul></div></div><div class="post-modal wx-share" id="wxShare"><a class="close" href="javascript:" id="wxShare-close">×</a><p>扫一扫，分享到微信</p><img src="//api.qrserver.com/v1/create-qr-code/?data=https://www.hosiang.cn/2b4e32ca/" alt="微信分享二维码"></div><div class="mask"></div><ul class="article-footer-menu"><li class="article-footer-tags"><i class="fa fa-tags"></i> <a href="/tags/Popular/" class="color3">Popular</a></li></ul></footer></div></article><aside class="post-toc-pos post-toc-top" id="post-toc"><nav class="post-toc-wrap"><ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%AE%80%E5%8C%96%E5%88%86%E5%B8%83%E5%BC%8F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E7%A8%8B"><span class="post-toc-text">简化分布式深度学习编程</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%9F%BA%E4%BA%8E-ElasticDL-%E6%A1%86%E6%9E%B6%E7%9A%84%E7%BC%96%E7%A8%8B"><span class="post-toc-text">基于 ElasticDL 框架的编程</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%B8%80%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="post-toc-text">一个例子</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#ElasticDL-%E7%9A%84%E5%BC%B9%E6%80%A7%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="post-toc-text">ElasticDL 的弹性训练过程</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Master-%E8%B4%9F%E8%B4%A3%E5%8A%A8%E6%80%81%E6%95%B0%E6%8D%AE%E5%88%92%E5%88%86"><span class="post-toc-text">Master 负责动态数据划分</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Woker-%E8%B0%83%E7%94%A8-TensorFlow-Eager-Execution"><span class="post-toc-text">Woker 调用 TensorFlow Eager Execution</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E9%AB%98%E6%95%88%E8%AE%AD%E7%BB%83%E7%9A%84%E4%BC%98%E5%8C%96"><span class="post-toc-text">高效训练的优化</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%BC%B9%E6%80%A7%E8%B0%83%E5%BA%A6%E6%8F%90%E5%8D%87%E9%9B%86%E7%BE%A4%E5%88%A9%E7%94%A8%E7%8E%87"><span class="post-toc-text">弹性调度提升集群利用率</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%B8%80%EF%BC%9A%E5%A4%9A%E4%B8%AA-AI-%E8%AE%AD%E7%BB%83%E4%BD%9C%E4%B8%9A%E5%B9%B6%E5%8F%91"><span class="post-toc-text">实验一：多个 AI 训练作业并发</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%BA%8C%EF%BC%9AAI-%E4%BD%9C%E4%B8%9A%E5%92%8C%E5%9C%A8%E7%BA%BF%E6%9C%8D%E5%8A%A1%E6%B7%B7%E5%B8%83"><span class="post-toc-text">实验二：AI 作业和在线服务混布</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%B8%89%EF%BC%9A%E8%AE%AD%E7%BB%83%E6%97%B6%E6%9B%B4%E6%94%B9-worker-%E6%95%B0%E9%87%8F%E4%B8%8D%E5%BD%B1%E5%93%8D%E6%94%B6%E6%95%9B%E6%80%A7"><span class="post-toc-text">实验三：训练时更改 worker 数量不影响收敛性</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%80%BB%E7%BB%93"><span class="post-toc-text">总结</span></a></li></ol></nav></aside><nav id="article-nav"><a href="/2edec8a8/" id="article-nav-newer" class="article-nav-link-wrap"><span class="article-nav-title"><i class="fa fa-hand-o-left" aria-hidden="true"></i> 推荐系列-探究 Go 语言 defer 语句的三种机制 </span></a><a href="/234a4633/" id="article-nav-older" class="article-nav-link-wrap"><span class="article-nav-title">推荐系列-深入了解kafka系列-消费者</span> <i class="fa fa-hand-o-right" aria-hidden="true"></i></a></nav><div id="gitalk"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script>var gitalk=new Gitalk({repo:"bolg-comment",owner:"Hosiang1026",admin:"Hosiang1026",clientID:"37a2dd4473e8970cecc2",clientSecret:"e30efa17d86d9de4f4ab810872dc62a7b2e7e634",pagerDirection:"last",distractionFreeMode:!0,createIssueManually:!1});gitalk.render("gitalk")</script></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner"><script id="_wau78w">var _wau=_wau||[];_wau.push(["small","5dnguv4c2n","78w"])</script><script async src="//waust.at/s.js"></script><p><span id="busuanzi_container_site_uv" style="display:none"><span class="post-count">总字数：<span>1777.3k</span> </span>总访客数：<span id="busuanzi_value_site_uv"></span> </span><span id="busuanzi_container_site_pv" style="display:none">总访问量：<span id="busuanzi_value_site_pv"></span></span><br><span id="TimeShow">本站</span><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><br>Copyright&copy; 2018 - 2022 狂欢马克思 <a href="https://beian.miit.gov.cn" rel="external nofollow noopener noreferrer" target="_blank">京ICP备17060439号</a></p></div></div><script>var now=new Date;function createtime(){var n=new Date("2017/09/18");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="安全运行 "+dnum+" 天 ",document.getElementById("times").innerHTML=hnum+" 小时 "+mnum+" 分 "+snum+" 秒"}setInterval("createtime()",800)</script></footer><script>var mihoConfig={root:"https://www.hosiang.cn",animate:"true",isHome:"false",share:"true",reward:" 1"}</script><div class="sidebar"><div id="sidebar-search" title="Search"><i class="fa fa-search"></i></div><div id="sidebar-category" title="Categories"><i class="fa fa-book"></i></div><div id="sidebar-tag" title="Tags"><i class="fa fa-tags"></i></div><div id="sidebar-top"><span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span></div></div><div class="sidebar-menu-box" id="sidebar-menu-box"><div class="sidebar-menu-box-container"><div id="sidebar-menu-box-categories"><a class="category-link" href="/categories/%E5%85%B4%E8%B6%A3%E7%88%B1%E5%A5%BD/">兴趣爱好</a><a class="category-link" href="/categories/%E5%85%B6%E4%BB%96%E5%BC%80%E5%8F%91/">其他开发</a><a class="category-link" href="/categories/%E5%89%8D%E6%B2%BF%E5%BC%80%E5%8F%91/">前沿开发</a><a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/">前端开发</a><a class="category-link" href="/categories/%E5%8D%87%E7%BA%A7%E7%89%88%E6%9C%AC/">升级版本</a><a class="category-link" href="/categories/%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B/">博客教程</a><a class="category-link" href="/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/">后端开发</a><a class="category-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a><a class="category-link" href="/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/">日常记录</a><a class="category-link" href="/categories/%E7%83%AD%E9%97%A8%E6%96%87%E7%AB%A0/">热门文章</a></div><div id="sidebar-menu-box-tags"><a href="/tags/Ajax/" style="font-size:10px">Ajax</a> <a href="/tags/AliGenie/" style="font-size:10px">AliGenie</a> <a href="/tags/Alipay/" style="font-size:10px">Alipay</a> <a href="/tags/Android/" style="font-size:10px">Android</a> <a href="/tags/Blockchain/" style="font-size:17.5px">Blockchain</a> <a href="/tags/CQRS/" style="font-size:10px">CQRS</a> <a href="/tags/Database/" style="font-size:15px">Database</a> <a href="/tags/Docker/" style="font-size:10px">Docker</a> <a href="/tags/EasyUI/" style="font-size:10px">EasyUI</a> <a href="/tags/Guitar/" style="font-size:10px">Guitar</a> <a href="/tags/Hackintosh/" style="font-size:12.5px">Hackintosh</a> <a href="/tags/Hexo/" style="font-size:15px">Hexo</a> <a href="/tags/IntelliJ-IDEA/" style="font-size:10px">IntelliJ IDEA</a> <a href="/tags/Java/" style="font-size:12.5px">Java</a> <a href="/tags/Kali-Linux/" style="font-size:10px">Kali Linux</a> <a href="/tags/Life/" style="font-size:17.5px">Life</a> <a href="/tags/Mac-OS/" style="font-size:12.5px">Mac OS</a> <a href="/tags/MultiThread/" style="font-size:10px">MultiThread</a> <a href="/tags/NodeJS/" style="font-size:10px">NodeJS</a> <a href="/tags/Popular/" style="font-size:20px">Popular</a> <a href="/tags/Python/" style="font-size:10px">Python</a> <a href="/tags/SaaS/" style="font-size:10px">SaaS</a> <a href="/tags/Servlet/" style="font-size:10px">Servlet</a> <a href="/tags/Spring/" style="font-size:17.5px">Spring</a> <a href="/tags/Upgrade/" style="font-size:10px">Upgrade</a> <a href="/tags/Web/" style="font-size:10px">Web</a> <a href="/tags/Windows/" style="font-size:10px">Windows</a> <a href="/tags/Work/" style="font-size:10px">Work</a> <a href="/tags/iOS/" style="font-size:10px">iOS</a></div></div><a href="javascript:" class="sidebar-menu-box-close">&times;</a></div><div class="mobile-header-menu-nav" id="mobile-header-menu-nav"><div class="mobile-header-menu-container"><span class="title">导航</span><ul class="mobile-header-menu-navbar"><li><a href="/"><i class="fa fa-home"></i><span>主页</span></a></li><li><a href="/archives"><i class="fa fa-archive"></i><span>归档</span></a></li><li><a href="/gitbook"><i class="fa fa-columns"></i><span>笔记</span></a></li><li><a href="/music"><i class="fa fa-music"></i><span>音乐</span></a></li><li><a href="/photo"><i class="fa fa-picture-o"></i><span>相册</span></a></li><li><a href="/love"><i class="fa fa-heart"></i><span>恋爱</span></a></li><li><a href="/collection"><i class="fa fa-envira"></i><span>收藏</span></a></li><li><a href="/about"><i class="fa fa-user"></i><span>关于</span></a></li></ul></div><div class="mobile-header-tag-container"><span class="title">标签</span><div id="mobile-header-container-tags"><a href="/tags/Ajax/" style="font-size:10px">Ajax</a> <a href="/tags/AliGenie/" style="font-size:10px">AliGenie</a> <a href="/tags/Alipay/" style="font-size:10px">Alipay</a> <a href="/tags/Android/" style="font-size:10px">Android</a> <a href="/tags/Blockchain/" style="font-size:17.5px">Blockchain</a> <a href="/tags/CQRS/" style="font-size:10px">CQRS</a> <a href="/tags/Database/" style="font-size:15px">Database</a> <a href="/tags/Docker/" style="font-size:10px">Docker</a> <a href="/tags/EasyUI/" style="font-size:10px">EasyUI</a> <a href="/tags/Guitar/" style="font-size:10px">Guitar</a> <a href="/tags/Hackintosh/" style="font-size:12.5px">Hackintosh</a> <a href="/tags/Hexo/" style="font-size:15px">Hexo</a> <a href="/tags/IntelliJ-IDEA/" style="font-size:10px">IntelliJ IDEA</a> <a href="/tags/Java/" style="font-size:12.5px">Java</a> <a href="/tags/Kali-Linux/" style="font-size:10px">Kali Linux</a> <a href="/tags/Life/" style="font-size:17.5px">Life</a> <a href="/tags/Mac-OS/" style="font-size:12.5px">Mac OS</a> <a href="/tags/MultiThread/" style="font-size:10px">MultiThread</a> <a href="/tags/NodeJS/" style="font-size:10px">NodeJS</a> <a href="/tags/Popular/" style="font-size:20px">Popular</a> <a href="/tags/Python/" style="font-size:10px">Python</a> <a href="/tags/SaaS/" style="font-size:10px">SaaS</a> <a href="/tags/Servlet/" style="font-size:10px">Servlet</a> <a href="/tags/Spring/" style="font-size:17.5px">Spring</a> <a href="/tags/Upgrade/" style="font-size:10px">Upgrade</a> <a href="/tags/Web/" style="font-size:10px">Web</a> <a href="/tags/Windows/" style="font-size:10px">Windows</a> <a href="/tags/Work/" style="font-size:10px">Work</a> <a href="/tags/iOS/" style="font-size:10px">iOS</a></div></div></div><div class="search-wrap"><span class="search-close">&times;</span> <a href="javascript:" class="header-icon waves-effect waves-circle waves-light" id="back"><i class="icon icon-lg icon-chevron-left"></i> </a><input class="search-field" placeholder="Search..." id="keywords"> <a id="search-submit" href="javascript:"><i class="fa fa-search"></i></a><div class="search-container" id="search-container"><ul class="search-result" id="search-result"></ul></div></div><div id="search-tpl"><li class="search-result-item"><a href="{url}" class="search-item-li"><span class="search-item-li-title" title="{title}">{title}</span></a></li></div><script src="/js/search.js"></script><script src="/js/main.js"></script><script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script><div id="particles"></div><script src="/js/particles.js"></script><link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css"><script src="//cdn.bootcss.com/scrollReveal.js/3.0.5/scrollreveal.js"></script><script src="/js/animate.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{jsonPath:"/live2dw/assets/hijiki.model.json"},display:{position:"right",width:150,height:300},mobile:{show:!0,scale:.5},log:!1})</script></body></html>