<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="Access-Control-Allow-Origin" content="*"><script type="text/javascript">var start_time=(new Date).getTime()</script><meta http-equiv="Cache-Control" content="no-cache"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="viewport" content="initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="baidu-site-verification" content="codeva-JcuFKkCTW2"><meta name="google-site-verification" content="GOa_MDr6Uz7cL7SHoNQIoPhiBCMp1WMlUeUa8avuIOg"><meta name="360-site-verification" content="2a299bcaf5d0e17606cbc47c55252c34"><meta name="baidu_union_verify" content="7fdc0fcf59a6c750e39da4f72040c01e"><title>推荐系列-使用 PAI-Blade 优化 Stable Diffusion 推理流程 | 狂欢马克思</title><meta name="keywords" content="分享技术经验与交流"><meta name="description" content="&amp;emsp;&amp;emsp; AIGC是人工智能计算领域里发展迅速的重要业务。Stable Diffusion 是其中最热门的开源模型，受到广泛关注。然而，随着应用场景不断扩大，Stable Diffusion所面临的推理时延和计算成本问题…"><meta property="og:type" content="article"><meta property="og:title" content="推荐系列-使用 PAI-Blade 优化 Stable Diffusion 推理流程"><meta property="og:url" content="https://haoxiang.eu.org/38f3095f/index.html"><meta property="og:site_name" content="狂欢马克思"><meta property="og:description" content="&amp;emsp;&amp;emsp; AIGC是人工智能计算领域里发展迅速的重要业务。Stable Diffusion 是其中最热门的开源模型，受到广泛关注。然而，随着应用场景不断扩大，Stable Diffusion所面临的推理时延和计算成本问题…"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2023-05-24T01:23:09.000Z"><meta property="article:modified_time" content="2023-06-29T07:10:21.052Z"><meta property="article:author" content="Howe Hsiang"><meta property="article:tag" content="Popular"><meta name="twitter:card" content="summary"><link rel="icon" href="/images/favicon.ico"><link href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"><link href="https://cdn.bootcss.com/font-awesome-animation/0.1.0/font-awesome-animation.min.css" rel="stylesheet"><link rel="stylesheet" href="/css/style.css"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?3cd8fa109426bf3f10bd5c362175bace";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta name="generator" content="Hexo 6.3.0"></head><script src="/js/jquery.min.js"></script><script src="/js/pace.min.js"></script><script src="/js/crypto-js.js"></script><script src="/js/cookie.js"></script><script src="/js/calendar.js"></script><script src="/js/festival.js"></script><script>getFestival()</script><body><script>window.onload=function(){document.getElementById("TimeShow").innerHTML="本站耗时 "+((new Date).getTime()-start_time)/1e3+" 秒 "}</script><div id="container"><header id="header"><div id="banner"></div><div id="header-outer"><div id="header-menu" class="header-menu-pos animated"><div class="header-menu-container"><a href="/" class="left"><span class="site-title">狂欢马克思</span></a><nav id="header-menu-nav" class="right"><a href="/" rel="external nofollow"><i class="fa fa-home"></i> <span>主页</span> </a><a href="/archives" rel="external nofollow"><i class="fa fa-archive"></i> <span>归档</span> </a><a href="/gitbook" rel="external nofollow"><i class="fa fa-columns"></i> <span>笔记</span> </a><a href="/photo" rel="external nofollow"><i class="fa fa-picture-o"></i> <span>相册</span> </a><a href="/love" rel="external nofollow"><i class="fa fa-heart"></i> <span>恋爱</span> </a><a href="/collection" rel="external nofollow"><i class="fa fa-envira"></i> <span>收藏</span> </a><a href="/about" rel="external nofollow"><i class="fa fa-user"></i> <span>关于</span></a></nav><a class="mobile-header-menu-button"><i class="fa fa-bars"></i></a></div></div><div id="header-row"><div id="logo"><a href="/"><img src="/../images/logo.png" alt="logo"></a></div><div class="header-info"><div id="header-title"><h2>狂欢马克思</h2></div><div id="header-description"><h3>专注Web开发</h3></div></div><nav class="header-nav"><div class="social"><a title="Github" target="_blank" href="//github.com/Hosiang1026" rel="external nofollow"><i class="fa fa-github fa-2x"></i></a> <a title="QQ" target="_blank" href="//wpa.qq.com/msgrd?v=3&uin=641904695&site=qq&menu=yes" rel="external nofollow"><i class="fa fa-qq fa-2x"></i></a> <a title="Weibo" target="_blank" href="//www.weibo.com/haoxiang969" rel="external nofollow"><i class="fa fa-weibo fa-2x"></i></a></div></nav></div><script type="text/javascript" src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script><div id="noticeId" class="show" style="background:rgb(244,247,247,.3)"><marquee id="noticeMar" behavior="scoll" class="notice" direction="left" onmouseover="this.stop()" onmouseout="this.start()"></marquee></div><script type="text/javascript">function browserRedirect(){var i=navigator.userAgent.toLowerCase(),n="ipad"==i.match(/ipad/i),e="iphone os"==i.match(/iphone os/i),o="midp"==i.match(/midp/i),a="rv:1.2.3.4"==i.match(/rv:1.2.3.4/i),s="ucweb"==i.match(/ucweb/i),t="android"==i.match(/android/i),r="windows ce"==i.match(/windows ce/i),c="windows mobile"==i.match(/windows mobile/i),d="",m=randomColor(),d=n||e||o||a||s||t||r||c?($("#noticeId").css({"line-height":"1.6em"}),"<font style='color:"+m+"' face='新华宋体'  size='2'>官宣：<span id='msg'></span><span id='timer'></span><span id='jinrishici-sentence'></span></font> "):($("#noticeId").css({"line-height":"3.6em","margin-top":"20px"}),"<font style='color:"+m+"' face='新华宋体'  size='6'>官宣：<span id='weekend'></span><span id='msg'></span><span id='timer'></span><span id='jinrishici-sentence'></span></font> ");$("#noticeMar").html(d)}function randomColor(){for(var i="0,1,2,3,4,5,6,7,8,9,a,b,c,d,e,f".split(","),n="#",e=0;e<6;e++)n+=i[Math.floor(16*Math.random())];return n}$(function(){browserRedirect()})</script></div></header><script>console.log=function(){}</script><div class="outer"><section id="main" class="body-wrap"><article id="post-sync/使用 PAI-Blade 优化 Stable Diffusion 推理流程" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 class="post-title" itemprop="name">推荐系列-使用 PAI-Blade 优化 Stable Diffusion 推理流程</h1><div class="post-title-bar"><ul><li><i class="fa fa-book"></i> <a href="/categories/热门文章/">热门文章</a></li><li><i class="fa fa-calendar"></i> 2023-05-24</li><li><i class="fa fa-eye"></i> <span id="busuanzi_value_page_pv"></span></li><li><span class="post-count">字数统计: 1.6k字</span></li><li><span class="post-count">阅读时长: 6分钟</span></li></ul></div></header><div class="article-entry post-content" itemprop="articleBody"><p>&amp;emsp;&amp;emsp; AIGC是人工智能计算领域里发展迅速的重要业务。Stable Diffusion 是其中最热门的开源模型，受到广泛关注。然而，随着应用场景不断扩大，Stable Diffusion所面临的推理时延和计算成本问题…</p><span id="more"></span><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><h2 id="AIGC是人工智能计算领域里发展迅速的重要业务。Stable-Diffusion-是其中最热门的开源模型���受到广泛关注。然而，随着应用场景不断扩大，Stable-Diffusion所面临的推理时延和计算成本问题也越来越突出。-简介PAI-Blade是-PAI-推出的通用推理优化工具，可以通过模型系统联合优化，使模型达到最优推理性能。PAI-Blade依托于完全动态尺寸的AI编译器BladeDISC-和-基于深度学习自动调度的高性能计算库BlaDNN，-为包括图像生成模型Stable-Diffsuion-大语言模型LLM-大规模稀疏推荐模型CTR-语音识别模型ASR等等在内的众多模型提供自动的高性能推理优化。BladeDISC-是一款支持完全动态尺寸的AI编译器，前端支持Pytorch和Tensorflow模型。对于Pytorch模型能够支持-TorchScript-和-TorchDynamo-两种输入模式，后端通过-AStitch-大尺度算子融合技术和高效的-codegen-逻辑提升模型访存密集算子的执行效率。BladeDISC现已在github开源，项目地址：https-github-com-alibaba-BladeDISC-。BlaDNN-是基于深度学习自动调度的高性能计算库。BlaDNN-作为Ansor的升级版，不仅生成的kernel性能超过Ansor，而且可以完全依赖DNN自动调度而不使用Tuning调优，使得Dynamic-Shape业务场景的在线自动调度成为可能，基于DNN自动调度生成的GPU计算密集算子的平均性能达到极致tuning性能的99-39-，通过模型系统联合优化DNN推理延时低至2us-并且只使用一个CPU-Core，从而不会对GPU模型本身的性能造成任何抖动。通过采用-PAI-Blade-加速推理优化技术，对访存密集型算子进行大尺度融合及优化代码生成，对计算密集型算子进行自动调度，可以大幅度降低Stable-Diffusion的推理延迟和显存占用，从而减少计算成本。使用-PAI-Blade-优化Stable-Diffusion-具有以下三点优势：-高性能，使用Blade可以降低-Text2Img、Img2Img-等推理流程的端到端延迟-2-42-3-05-倍，同时可降低省显存占用至多-5-27-倍，超过TensorRT-8-5等业内SOTA优化手段。-完全动态shape支持，一次优化后，可以支持任意形状、batch-size的输入。-易用性、可扩展性：仅需数行代码即可在多类pipeline中启用-Blade优化，同时能支持LoRA等推理方案的优化。-使用示例本文接下来以社区流行的-“runwayml-x2F-stable-diffusion-v1-5”-的-Text2Img-pipeline-为例，详细介绍-PAI-Blade-在各类使用场景下的使用方法。-环境安装下述示例完整的运行脚本及相关环境已集成到-docker-中。在该docker中，直接通过-即可运行推理示例。-官方模型优化使用-PAI-Blade-优化-Stable-Diffusion-模型可以分为以下几个步骤。首先，加载预训练的模型。-第二步，使用-PAI-Blade-进行优化。注意，由于-PAI-Blade-是完全动态shape的优化工具，优化完成后可使用任意shape进行推理。-最后，使用优化好的模型替换原始模型，后续即可以原始-pipeline-同样的方式进行推理。-A100-性能对比-image-size-samplesteps-Time-of-Pytorch-s-Time-of-PAI-Blade-s-speedup-Pytorch-memory-usage-GB-PAI-Blade-memory-usage-GB-1024x1024-50-13-26-4-34-3-06X-32-91-6-25-768x768-50-5-65-2-00-2-83X-14-99-5-91-512x512-50-2-24-0-84-2-67X-6-60-5-42-A10-性能对比-image-size-samplesteps-Time-of-Pytorch-s-Time-of-PAI-Blade-s-speedup-Pytorch-memory-usage-GB-PAI-Blade-memory-usage-GB-1024x1024-50-OOM-13-86"><a href="#AIGC是人工智能计算领域里发展迅速的重要业务。Stable-Diffusion-是其中最热门的开源模型���受到广泛关注。然而，随着应用场景不断扩大，Stable-Diffusion所面临的推理时延和计算成本问题也越来越突出。-简介PAI-Blade是-PAI-推出的通用推理优化工具，可以通过模型系统联合优化，使模型达到最优推理性能。PAI-Blade依托于完全动态尺寸的AI编译器BladeDISC-和-基于深度学习自动调度的高性能计算库BlaDNN，-为包括图像生成模型Stable-Diffsuion-大语言模型LLM-大规模稀疏推荐模型CTR-语音识别模型ASR等等在内的众多模型提供自动的高性能推理优化。BladeDISC-是一款支持完全动态尺寸的AI编译器，前端支持Pytorch和Tensorflow模型。对于Pytorch模型能够支持-TorchScript-和-TorchDynamo-两种输入模式，后端通过-AStitch-大尺度算子融合技术和高效的-codegen-逻辑提升模型访存密集算子的执行效率。BladeDISC现已在github开源，项目地址：https-github-com-alibaba-BladeDISC-。BlaDNN-是基于深度学习自动调度的高性能计算库。BlaDNN-作为Ansor的升级版，不仅生成的kernel性能超过Ansor，而且可以完全依赖DNN自动调度而不使用Tuning调优，使得Dynamic-Shape业务场景的在线自动调度成为可能，基于DNN自动调度生成的GPU计算密集算子的平均性能达到极致tuning性能的99-39-，通过模型系统联合优化DNN推理延时低至2us-并且只使用一个CPU-Core，从而不会对GPU模型本身的性能造成任何抖动。通过采用-PAI-Blade-加速推理优化技术，对访存密集型算子进行大尺度融合及优化代码生成，对计算密集型算子进行自动调度，可以大幅度降低Stable-Diffusion的推理延迟和显存占用，从而减少计算成本。使用-PAI-Blade-优化Stable-Diffusion-具有以下三点优势：-高性能，使用Blade可以降低-Text2Img、Img2Img-等推理流程的端到端延迟-2-42-3-05-倍，同时可降低省显存占用至多-5-27-倍，超过TensorRT-8-5等业内SOTA优化手段。-完全动态shape支持，一次优化后，可以支持任意形状、batch-size的输入。-易用性、可扩展性：仅需数行代码即可在多类pipeline中启用-Blade优化，同时能支持LoRA等推理方案的优化。-使用示例本文接下来以社区流行的-“runwayml-x2F-stable-diffusion-v1-5”-的-Text2Img-pipeline-为例，详细介绍-PAI-Blade-在各类使用场景下的使用方法。-环境安装下述示例完整的运行脚本及相关环境已集成到-docker-中。在该docker中，直接通过-即可运行推理示例。-官方模型优化使用-PAI-Blade-优化-Stable-Diffusion-模型可以分为以下几个步骤。首先，加载预训练的模型。-第二步，使用-PAI-Blade-进行优化。注意，由于-PAI-Blade-是完全动态shape的优化工具，优化完成后可使用任意shape进行推理。-最后，使用优化好的模型替换原始模型，后续即可以原始-pipeline-同样的方式进行推理。-A100-性能对比-image-size-samplesteps-Time-of-Pytorch-s-Time-of-PAI-Blade-s-speedup-Pytorch-memory-usage-GB-PAI-Blade-memory-usage-GB-1024x1024-50-13-26-4-34-3-06X-32-91-6-25-768x768-50-5-65-2-00-2-83X-14-99-5-91-512x512-50-2-24-0-84-2-67X-6-60-5-42-A10-性能对比-image-size-samplesteps-Time-of-Pytorch-s-Time-of-PAI-Blade-s-speedup-Pytorch-memory-usage-GB-PAI-Blade-memory-usage-GB-1024x1024-50-OOM-13-86" class="headerlink" title="AIGC是人工智能计算领域里发展迅速的重要业务。Stable Diffusion 是其中最热门的开源模型���受到广泛关注。然而，随着应用场景不断扩大，Stable Diffusion所面临的推理时延和计算成本问题也越来越突出。### 简介PAI-Blade是 PAI 推出的通用推理优化工具，可以通过模型系统联合优化，使模型达到最优推理性能。PAI-Blade依托于完全动态尺寸的AI编译器BladeDISC 和 基于深度学习自动调度的高性能计算库BlaDNN， 为包括图像生成模型Stable Diffsuion, 大语言模型LLM, 大规模稀疏推荐模型CTR, 语音识别模型ASR等等在内的众多模型提供自动的高性能推理优化。BladeDISC 是一款支持完全动态尺寸的AI编译器，前端支持Pytorch和Tensorflow模型。对于Pytorch模型能够支持 TorchScript 和 TorchDynamo 两种输入模式，后端通过 AStitch 大尺度算子融合技术和高效的 codegen 逻辑提升模型访存密集算子的执行效率。BladeDISC现已在github开源，项目地址：https://github.com/alibaba/BladeDISC 。BlaDNN 是基于深度学习自动调度的高性能计算库。BlaDNN 作为Ansor的升级版，不仅生成的kernel性能超过Ansor，而且可以完全依赖DNN自动调度而不使用Tuning调优，使得Dynamic Shape业务场景的在线自动调度成为可能，基于DNN自动调度生成的GPU计算密集算子的平均性能达到极致tuning性能的99.39%，通过模型系统联合优化DNN推理延时低至2us, 并且只使用一个CPU Core，从而不会对GPU模型本身的性能造成任何抖动。通过采用 PAI-Blade 加速推理优化技术，对访存密集型算子进行大尺度融合及优化代码生成，对计算密集型算子进行自动调度，可以大幅度降低Stable Diffusion的推理延迟和显存占用，从而减少计算成本。使用 PAI-Blade 优化Stable Diffusion 具有以下三点优势： 高性能，使用Blade可以降低 Text2Img、Img2Img 等推理流程的端到端延迟 2.42-3.05 倍，同时可降低省显存占用至多 5.27 倍，超过TensorRT-8.5等业内SOTA优化手段。 完全动态shape支持，一次优化后，可以支持任意形状、batch size的输入。 易用性、可扩展性：仅需数行代码即可在多类pipeline中启用 Blade优化，同时能支持LoRA等推理方案的优化。### 使用示例本文接下来以社区流行的 “runwayml&#x2F;stable-diffusion-v1-5” 的 Text2Img pipeline 为例，详细介绍 PAI-Blade 在各类使用场景下的使用方法。#### 环境安装下述示例完整的运行脚本及相关环境已集成到   docker 中。在该docker中，直接通过   即可运行推理示例。#### 官方模型优化使用 PAI-Blade 优化 Stable Diffusion 模型可以分为以下几个步骤。首先，加载预训练的模型。 第二步，使用 PAI-Blade 进行优化。注意，由于 PAI-Blade 是完全动态shape的优化工具，优化完成后可使用任意shape进行推理。 最后，使用优化好的模型替换原始模型，后续即可以原始 pipeline 同样的方式进行推理。 ##### A100 性能对比   image size   samplesteps   Time of Pytorch(s)   Time of PAI-Blade(s)   speedup   Pytorch memory usage (GB)   PAI-Blade memory usage (GB)   1024x1024   50   13.26   4.34   3.06X   32.91   6.25   768x768   50   5.65   2.00   2.83X   14.99   5.91   512x512   50   2.24   0.84   2.67X   6.60   5.42##### A10 性能对比   image size   samplesteps   Time of Pytorch(s)   Time of PAI-Blade(s)   speedup   Pytorch memory usage (GB)   PAI-Blade memory usage (GB)   1024x1024   50   OOM   13.86 "></a>AIGC是人工智能计算领域里发展迅速的重要业务。Stable Diffusion 是其中最热门的开源模型���受到广泛关注。然而，随着应用场景不断扩大，Stable Diffusion所面临的推理时延和计算成本问题也越来越突出。<br><br>### 简介<br>PAI-Blade是 PAI 推出的通用推理优化工具，可以通过模型系统联合优化，使模型达到最优推理性能。PAI-Blade依托于完全动态尺寸的AI编译器BladeDISC 和 基于深度学习自动调度的高性能计算库BlaDNN， 为包括图像生成模型Stable Diffsuion, 大语言模型LLM, 大规模稀疏推荐模型CTR, 语音识别模型ASR等等在内的众多模型提供自动的高性能推理优化。<br>BladeDISC 是一款支持完全动态尺寸的AI编译器，前端支持Pytorch和Tensorflow模型。对于Pytorch模型能够支持 TorchScript 和 TorchDynamo 两种输入模式，后端通过 AStitch 大尺度算子融合技术和高效的 codegen 逻辑提升模型访存密集算子的执行效率。BladeDISC现已在github开源，项目地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/alibaba/BladeDISC">https://github.com/alibaba/BladeDISC</a> 。<br>BlaDNN 是基于深度学习自动调度的高性能计算库。BlaDNN 作为Ansor的升级版，不仅生成的kernel性能超过Ansor，而且可以完全依赖DNN自动调度而不使用Tuning调优，使得Dynamic Shape业务场景的在线自动调度成为可能，基于DNN自动调度生成的GPU计算密集算子的平均性能达到极致tuning性能的99.39%，通过模型系统联合优化DNN推理延时低至2us, 并且只使用一个CPU Core，从而不会对GPU模型本身的性能造成任何抖动。<br>通过采用 PAI-Blade 加速推理优化技术，对访存密集型算子进行大尺度融合及优化代码生成，对计算密集型算子进行自动调度，可以大幅度降低Stable Diffusion的推理延迟和显存占用，从而减少计算成本。使用 PAI-Blade 优化Stable Diffusion 具有以下三点优势：<br><br>高性能，使用Blade可以降低 Text2Img、Img2Img 等推理流程的端到端延迟 2.42-3.05 倍，同时可降低省显存占用至多 5.27 倍，超过TensorRT-8.5等业内SOTA优化手段。<br>完全动态shape支持，一次优化后，可以支持任意形状、batch size的输入。<br>易用性、可扩展性：仅需数行代码即可在多类pipeline中启用 Blade优化，同时能支持LoRA等推理方案的优化。<br><br><br>### 使用示例<br>本文接下来以社区流行的 “runwayml&#x2F;stable-diffusion-v1-5” 的 Text2Img pipeline 为例，详细介绍 PAI-Blade 在各类使用场景下的使用方法。<br><br>#### 环境安装<br>下述示例完整的运行脚本及相关环境已集成到<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">registry.cn-beijing.aliyuncs.com/blade_demo/blade_diffusion</span><br></pre></td></tr></table></figure><br>docker 中。在该docker中，直接通过<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python /blade/blade_diffusion.py</span><br></pre></td></tr></table></figure><br>即可运行推理示例。<br><br>#### 官方模型优化<br>使用 PAI-Blade 优化 Stable Diffusion 模型可以分为以下几个步骤。<br>首先，加载预训练的模型。<br><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  from diffusers <span class="keyword">import</span> <span class="type">StableDiffusionPipeline</span></span><br><span class="line"></span><br><span class="line"><span class="variable">device</span> <span class="operator">=</span> torch.device(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">pipe = StableDiffusionPipeline.from_pretrained(<span class="string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, revision=<span class="string">&quot;fp16&quot;</span>, torch_dtype=torch.float16).to(device)</span><br><span class="line"></span><br></pre></td></tr></table></figure><br><br>第二步，使用 PAI-Blade 进行优化。注意，由于 PAI-Blade 是完全动态shape的优化工具，优化完成后可使用任意shape进行推理。<br><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">import</span> <span class="type">torch_blade</span></span><br><span class="line"></span><br><span class="line"><span class="variable">opt_cfg</span> <span class="operator">=</span> torch_blade.Config()</span><br><span class="line">opt_cfg.enable_fp16 = True</span><br><span class="line">with opt_cfg, torch.no_grad():</span><br><span class="line">    encoder = blade_optimize(pipe.text_encoder, model_inputs=encoder_inputs, allow_tracing=True)</span><br><span class="line">    unet = blade_optimize(pipe.unet, model_inputs=unet_inputs, allow_tracing=True)</span><br><span class="line">    decoder = blade_optimize(pipe.vae.decoder, model_inputs=decoder_inputs, allow_tracing=True)</span><br><span class="line"></span><br></pre></td></tr></table></figure><br><br>最后，使用优化好的模型替换原始模型，后续即可以原始 pipeline 同样的方式进行推理。<br><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">  <span class="meta">@dataclass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UNet2DConditionOutput</span>:</span><br><span class="line">    sample: torch.FloatTensor</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TracedUNet</span>(torch.nn.Module):</span><br><span class="line">    def <span class="title function_">__init__</span><span class="params">(self)</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.config = pipe.unet.config</span><br><span class="line">        self.in_channels = pipe.unet.in_channels</span><br><span class="line">        self.device = pipe.unet.device</span><br><span class="line"></span><br><span class="line">    def <span class="title function_">forward</span><span class="params">(self, latent_model_input, t, encoder_hidden_states, **kwargs)</span>:</span><br><span class="line">        sample = unet(latent_model_input.half(), t.half(), encoder_hidden_states.half())[<span class="string">&quot;sample&quot;</span>]</span><br><span class="line">        <span class="keyword">return</span> UNet2DConditionOutput(sample=sample)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TracedEncoder</span>(torch.nn.Module):</span><br><span class="line">    def <span class="title function_">__init__</span><span class="params">(self)</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.config = pipe.text_encoder.config</span><br><span class="line">        self.device = pipe.text_encoder.device</span><br><span class="line">        self.dtype = torch.half</span><br><span class="line"></span><br><span class="line">    def <span class="title function_">forward</span><span class="params">(self, input_ids, **kwargs)</span>:</span><br><span class="line">        embeddings = encoder(input_ids.<span class="type">long</span>())</span><br><span class="line">        <span class="keyword">return</span> [embeddings[<span class="string">&quot;last_hidden_state&quot;</span>]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TracedDecoder</span>(torch.nn.Module):</span><br><span class="line">    def <span class="title function_">forward</span><span class="params">(self, input)</span>:</span><br><span class="line">        <span class="keyword">return</span> decoder(input.half())</span><br><span class="line"></span><br><span class="line">pipe.text_encoder = TracedEncoder()</span><br><span class="line">pipe.unet = TracedUNet()</span><br><span class="line">pipe.vae.decoder = TracedDecoder()</span><br><span class="line"></span><br></pre></td></tr></table></figure><br><br><br>##### A100 性能对比<br><br><br><br>image size<br>samplesteps<br>Time of Pytorch(s)<br>Time of PAI-Blade(s)<br>speedup<br>Pytorch memory usage (GB)<br>PAI-Blade memory usage (GB)<br><br><br><br><br>1024x1024<br>50<br>13.26<br>4.34<br>3.06X<br>32.91<br>6.25<br><br><br>768x768<br>50<br>5.65<br>2.00<br>2.83X<br>14.99<br>5.91<br><br><br>512x512<br>50<br>2.24<br>0.84<br>2.67X<br>6.60<br>5.42<br><br><br><br><br>##### A10 性能对比<br><br><br><br>image size<br>samplesteps<br>Time of Pytorch(s)<br>Time of PAI-Blade(s)<br>speedup<br>Pytorch memory usage (GB)<br>PAI-Blade memory usage (GB)<br><br><br><br><br>1024x1024<br>50<br>OOM<br>13.86</h2><p>OOM<br>6.89</p><p>768x768<br>50<br>13.13<br>5.61<br>2.34X<br>12.60<br>6.22</p><p>512x512<br>50<br>4.53<br>2.11<br>2.15X<br>6.28<br>5.47</p><h5 id="推理结果验证"><a href="#推理结果验证" class="headerlink" title="推理结果验证"></a>推理结果验证</h5><p>使用PAI-Blade优化后，生成的图像与Pytorch原始输出对比，观察优化结果是否正确。左图为Pytorch eager模式输出，右图为PAI-Blade优化后的模型输出。</p><h4 id="已验证的pipeline类型"><a href="#已验证的pipeline类型" class="headerlink" title="已验证的pipeline类型"></a>已验证的pipeline类型</h4><p>StableDiffusionPipeline<br>StableDiffusionImg2ImgPipeline<br>StableDiffusionInpaintPipeline<br>AltDiffusionPipeline</p><h4 id="LoRA优化"><a href="#LoRA优化" class="headerlink" title="LoRA优化"></a>LoRA优化</h4><p>LoRA 是指在原始模型基础上，添加额外的低秩矩阵来微调预训练的模型，并且只训练那些新添加的权重，从而大幅降低微调成本。可以通过 diffusers官方训练代码 微调得到 LoRA 权重。diffusers 加载使用 LoRA 后，模型运行方式与原始模型略有不同，带来额外计算开销。<br>PAI-Blade 目前已适配 huggingface&#x2F;diffusers 中 LoRA 优化方式。同样的，Blade 针对同一pipeline，只需优化一次，即可使用任意的 LoRA 权重进行推理。我们将在下一篇文章中介绍PAI-Blade 优化 LoRA 的使用方式，敬请期待。</p><h3 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h3><p>目前，Stable Diffusion相关技术仍在不断演化中，PAI-Blade 团队也时刻关注社区趋势，将优化适配到各种工具中去。目前团队主要集中在：</p><p>将相关优化集成到 stable-diffusion-webui 中；<br>优化 finetune 训练速度。</p><div class="post-copyright"><div class="content"><p>本文标题： 推荐系列-使用 PAI-Blade 优化 Stable Diffusion 推理流程</p><p>本文作者： OSChina</p><p>发布时间： 2023年05月24日 09:23</p><p>最后更新： 2023年06月29日 07:10</p><p>原始链接： <a class="post-url" href="/38f3095f/" title="推荐系列-使用 PAI-Blade 优化 Stable Diffusion 推理流程">https://haoxiang.eu.org/38f3095f/</a></p><p>版权声明： 本文著作权归作者所有，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noopener noreferrer" target="_blank">CC BY-NC-SA 4.0</a>许可协议，转载请注明出处！</p><footer><a href="https://haoxiang.eu.org"><img src="/../images/logo.png" alt="Howe Hsiang"> Howe Hsiang</a></footer></div></div><div class="page-reward"><a id="rewardBtn" href="javascript:;">赏</a></div><div id="reward" class="post-modal reward-lay"><a class="close" href="javascript:;" id="reward-close">×</a> <span class="reward-title"><i class="icon icon-quote-left"></i> 喜欢就赞赏一下呗！ <i class="icon icon-quote-right"></i></span><div class="reward-content"><div class="reward-code"><img id="rewardCode" src="/images/threepay_code.jpg" alt="打赏二维码"></div><div class="reward-select"></div></div></div></div><footer class="article-footer"><div class="post-share"><a href="javascript:" id="share-sub" class="post-share-fab"><i class="fa fa-share-alt" style="padding-top:11px!important"></i></a><div class="post-share-list" id="share-list"><ul class="share-icons"><li><a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://haoxiang.eu.org/38f3095f/" data-title="Facebook" rel="external nofollow noopener noreferrer"><i class="fa fa-facebook" style="padding-top:9px!important"></i></a></li><li><a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《推荐系列-使用 PAI-Blade 优化 Stable Diffusion 推理流程》 — 狂欢马克思&url=https://haoxiang.eu.org/38f3095f/&via=https://haoxiang.eu.org" data-title="Twitter" rel="external nofollow noopener noreferrer"><i class="fa fa-twitter" style="padding-top:9px!important"></i></a></li><li><a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://haoxiang.eu.org/38f3095f/" data-title="Google+" rel="external nofollow noopener noreferrer"><i class="fa fa-google-plus" style="padding-top:9px!important"></i></a></li><li><a class="qq share-sns" target="_blank" href="https://connect.qq.com/widget/shareqq/index.html?url=https://haoxiang.eu.org/38f3095f/&title=《推荐系列-使用 PAI-Blade 优化 Stable Diffusion 推理流程》 — 狂欢马克思&source=&amp;emsp;&amp;emsp; AIGC是人工智能计算领域里发展迅速的重要业务。Stable Diffusion 是其中最热门的开源模型，受到广..." data-title="QQ" rel="external nofollow noopener noreferrer"><i class="fa fa-qq" style="padding-top:9px!important"></i></a></li><li><a class="weixin share-sns" id="wxFab" href="javascript:" data-title="微信"><i class="fa fa-weixin" style="padding-top:9px!important"></i></a></li><li><a class="weibo share-sns" target="_blank" href="https://service.weibo.com/share/share.php?url=https://haoxiang.eu.org/38f3095f/&title=《推荐系列-使用 PAI-Blade 优化 Stable Diffusion 推理流程》 — 狂欢马克思&pic=https://api.ixiaowai.cn/gqapi/gqapi.php" data-title="微博" rel="external nofollow noopener noreferrer"><i class="fa fa-weibo" style="padding-top:9px!important"></i></a></li></ul></div></div><div class="post-modal wx-share" id="wxShare"><a class="close" href="javascript:" id="wxShare-close">×</a><p>扫一扫，分享到微信</p><img src="//api.qrserver.com/v1/create-qr-code/?data=https://haoxiang.eu.org/38f3095f/" alt="微信分享二维码"></div><div class="mask"></div><ul class="article-footer-menu"><li class="article-footer-tags"><i class="fa fa-tags"></i> <a href="/tags/Popular/" class="color3">Popular</a></li></ul></footer></div></article><aside class="post-toc-pos post-toc-top" id="post-toc"><nav class="post-toc-wrap"><ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%83%8C%E6%99%AF"><span class="post-toc-text">背景</span></a></li></ol><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#AIGC%E6%98%AF%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E9%A2%86%E5%9F%9F%E9%87%8C%E5%8F%91%E5%B1%95%E8%BF%85%E9%80%9F%E7%9A%84%E9%87%8D%E8%A6%81%E4%B8%9A%E5%8A%A1%E3%80%82Stable-Diffusion-%E6%98%AF%E5%85%B6%E4%B8%AD%E6%9C%80%E7%83%AD%E9%97%A8%E7%9A%84%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B%EF%BF%BD%EF%BF%BD%EF%BF%BD%E5%8F%97%E5%88%B0%E5%B9%BF%E6%B3%9B%E5%85%B3%E6%B3%A8%E3%80%82%E7%84%B6%E8%80%8C%EF%BC%8C%E9%9A%8F%E7%9D%80%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B8%8D%E6%96%AD%E6%89%A9%E5%A4%A7%EF%BC%8CStable-Diffusion%E6%89%80%E9%9D%A2%E4%B8%B4%E7%9A%84%E6%8E%A8%E7%90%86%E6%97%B6%E5%BB%B6%E5%92%8C%E8%AE%A1%E7%AE%97%E6%88%90%E6%9C%AC%E9%97%AE%E9%A2%98%E4%B9%9F%E8%B6%8A%E6%9D%A5%E8%B6%8A%E7%AA%81%E5%87%BA%E3%80%82-%E7%AE%80%E4%BB%8BPAI-Blade%E6%98%AF-PAI-%E6%8E%A8%E5%87%BA%E7%9A%84%E9%80%9A%E7%94%A8%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7%EF%BC%8C%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E8%81%94%E5%90%88%E4%BC%98%E5%8C%96%EF%BC%8C%E4%BD%BF%E6%A8%A1%E5%9E%8B%E8%BE%BE%E5%88%B0%E6%9C%80%E4%BC%98%E6%8E%A8%E7%90%86%E6%80%A7%E8%83%BD%E3%80%82PAI-Blade%E4%BE%9D%E6%89%98%E4%BA%8E%E5%AE%8C%E5%85%A8%E5%8A%A8%E6%80%81%E5%B0%BA%E5%AF%B8%E7%9A%84AI%E7%BC%96%E8%AF%91%E5%99%A8BladeDISC-%E5%92%8C-%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%8A%A8%E8%B0%83%E5%BA%A6%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%BA%93BlaDNN%EF%BC%8C-%E4%B8%BA%E5%8C%85%E6%8B%AC%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8BStable-Diffsuion-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BLLM-%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%A8%80%E7%96%8F%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8BCTR-%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8BASR%E7%AD%89%E7%AD%89%E5%9C%A8%E5%86%85%E7%9A%84%E4%BC%97%E5%A4%9A%E6%A8%A1%E5%9E%8B%E6%8F%90%E4%BE%9B%E8%87%AA%E5%8A%A8%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96%E3%80%82BladeDISC-%E6%98%AF%E4%B8%80%E6%AC%BE%E6%94%AF%E6%8C%81%E5%AE%8C%E5%85%A8%E5%8A%A8%E6%80%81%E5%B0%BA%E5%AF%B8%E7%9A%84AI%E7%BC%96%E8%AF%91%E5%99%A8%EF%BC%8C%E5%89%8D%E7%AB%AF%E6%94%AF%E6%8C%81Pytorch%E5%92%8CTensorflow%E6%A8%A1%E5%9E%8B%E3%80%82%E5%AF%B9%E4%BA%8EPytorch%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%A4%9F%E6%94%AF%E6%8C%81-TorchScript-%E5%92%8C-TorchDynamo-%E4%B8%A4%E7%A7%8D%E8%BE%93%E5%85%A5%E6%A8%A1%E5%BC%8F%EF%BC%8C%E5%90%8E%E7%AB%AF%E9%80%9A%E8%BF%87-AStitch-%E5%A4%A7%E5%B0%BA%E5%BA%A6%E7%AE%97%E5%AD%90%E8%9E%8D%E5%90%88%E6%8A%80%E6%9C%AF%E5%92%8C%E9%AB%98%E6%95%88%E7%9A%84-codegen-%E9%80%BB%E8%BE%91%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E8%AE%BF%E5%AD%98%E5%AF%86%E9%9B%86%E7%AE%97%E5%AD%90%E7%9A%84%E6%89%A7%E8%A1%8C%E6%95%88%E7%8E%87%E3%80%82BladeDISC%E7%8E%B0%E5%B7%B2%E5%9C%A8github%E5%BC%80%E6%BA%90%EF%BC%8C%E9%A1%B9%E7%9B%AE%E5%9C%B0%E5%9D%80%EF%BC%9Ahttps-github-com-alibaba-BladeDISC-%E3%80%82BlaDNN-%E6%98%AF%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%8A%A8%E8%B0%83%E5%BA%A6%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97%E5%BA%93%E3%80%82BlaDNN-%E4%BD%9C%E4%B8%BAAnsor%E7%9A%84%E5%8D%87%E7%BA%A7%E7%89%88%EF%BC%8C%E4%B8%8D%E4%BB%85%E7%94%9F%E6%88%90%E7%9A%84kernel%E6%80%A7%E8%83%BD%E8%B6%85%E8%BF%87Ansor%EF%BC%8C%E8%80%8C%E4%B8%94%E5%8F%AF%E4%BB%A5%E5%AE%8C%E5%85%A8%E4%BE%9D%E8%B5%96DNN%E8%87%AA%E5%8A%A8%E8%B0%83%E5%BA%A6%E8%80%8C%E4%B8%8D%E4%BD%BF%E7%94%A8Tuning%E8%B0%83%E4%BC%98%EF%BC%8C%E4%BD%BF%E5%BE%97Dynamic-Shape%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E7%9A%84%E5%9C%A8%E7%BA%BF%E8%87%AA%E5%8A%A8%E8%B0%83%E5%BA%A6%E6%88%90%E4%B8%BA%E5%8F%AF%E8%83%BD%EF%BC%8C%E5%9F%BA%E4%BA%8EDNN%E8%87%AA%E5%8A%A8%E8%B0%83%E5%BA%A6%E7%94%9F%E6%88%90%E7%9A%84GPU%E8%AE%A1%E7%AE%97%E5%AF%86%E9%9B%86%E7%AE%97%E5%AD%90%E7%9A%84%E5%B9%B3%E5%9D%87%E6%80%A7%E8%83%BD%E8%BE%BE%E5%88%B0%E6%9E%81%E8%87%B4tuning%E6%80%A7%E8%83%BD%E7%9A%8499-39-%EF%BC%8C%E9%80%9A%E8%BF%87%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E8%81%94%E5%90%88%E4%BC%98%E5%8C%96DNN%E6%8E%A8%E7%90%86%E5%BB%B6%E6%97%B6%E4%BD%8E%E8%87%B32us-%E5%B9%B6%E4%B8%94%E5%8F%AA%E4%BD%BF%E7%94%A8%E4%B8%80%E4%B8%AACPU-Core%EF%BC%8C%E4%BB%8E%E8%80%8C%E4%B8%8D%E4%BC%9A%E5%AF%B9GPU%E6%A8%A1%E5%9E%8B%E6%9C%AC%E8%BA%AB%E7%9A%84%E6%80%A7%E8%83%BD%E9%80%A0%E6%88%90%E4%BB%BB%E4%BD%95%E6%8A%96%E5%8A%A8%E3%80%82%E9%80%9A%E8%BF%87%E9%87%87%E7%94%A8-PAI-Blade-%E5%8A%A0%E9%80%9F%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF%EF%BC%8C%E5%AF%B9%E8%AE%BF%E5%AD%98%E5%AF%86%E9%9B%86%E5%9E%8B%E7%AE%97%E5%AD%90%E8%BF%9B%E8%A1%8C%E5%A4%A7%E5%B0%BA%E5%BA%A6%E8%9E%8D%E5%90%88%E5%8F%8A%E4%BC%98%E5%8C%96%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90%EF%BC%8C%E5%AF%B9%E8%AE%A1%E7%AE%97%E5%AF%86%E9%9B%86%E5%9E%8B%E7%AE%97%E5%AD%90%E8%BF%9B%E8%A1%8C%E8%87%AA%E5%8A%A8%E8%B0%83%E5%BA%A6%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%A4%A7%E5%B9%85%E5%BA%A6%E9%99%8D%E4%BD%8EStable-Diffusion%E7%9A%84%E6%8E%A8%E7%90%86%E5%BB%B6%E8%BF%9F%E5%92%8C%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%EF%BC%8C%E4%BB%8E%E8%80%8C%E5%87%8F%E5%B0%91%E8%AE%A1%E7%AE%97%E6%88%90%E6%9C%AC%E3%80%82%E4%BD%BF%E7%94%A8-PAI-Blade-%E4%BC%98%E5%8C%96Stable-Diffusion-%E5%85%B7%E6%9C%89%E4%BB%A5%E4%B8%8B%E4%B8%89%E7%82%B9%E4%BC%98%E5%8A%BF%EF%BC%9A-%E9%AB%98%E6%80%A7%E8%83%BD%EF%BC%8C%E4%BD%BF%E7%94%A8Blade%E5%8F%AF%E4%BB%A5%E9%99%8D%E4%BD%8E-Text2Img%E3%80%81Img2Img-%E7%AD%89%E6%8E%A8%E7%90%86%E6%B5%81%E7%A8%8B%E7%9A%84%E7%AB%AF%E5%88%B0%E7%AB%AF%E5%BB%B6%E8%BF%9F-2-42-3-05-%E5%80%8D%EF%BC%8C%E5%90%8C%E6%97%B6%E5%8F%AF%E9%99%8D%E4%BD%8E%E7%9C%81%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E8%87%B3%E5%A4%9A-5-27-%E5%80%8D%EF%BC%8C%E8%B6%85%E8%BF%87TensorRT-8-5%E7%AD%89%E4%B8%9A%E5%86%85SOTA%E4%BC%98%E5%8C%96%E6%89%8B%E6%AE%B5%E3%80%82-%E5%AE%8C%E5%85%A8%E5%8A%A8%E6%80%81shape%E6%94%AF%E6%8C%81%EF%BC%8C%E4%B8%80%E6%AC%A1%E4%BC%98%E5%8C%96%E5%90%8E%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%94%AF%E6%8C%81%E4%BB%BB%E6%84%8F%E5%BD%A2%E7%8A%B6%E3%80%81batch-size%E7%9A%84%E8%BE%93%E5%85%A5%E3%80%82-%E6%98%93%E7%94%A8%E6%80%A7%E3%80%81%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7%EF%BC%9A%E4%BB%85%E9%9C%80%E6%95%B0%E8%A1%8C%E4%BB%A3%E7%A0%81%E5%8D%B3%E5%8F%AF%E5%9C%A8%E5%A4%9A%E7%B1%BBpipeline%E4%B8%AD%E5%90%AF%E7%94%A8-Blade%E4%BC%98%E5%8C%96%EF%BC%8C%E5%90%8C%E6%97%B6%E8%83%BD%E6%94%AF%E6%8C%81LoRA%E7%AD%89%E6%8E%A8%E7%90%86%E6%96%B9%E6%A1%88%E7%9A%84%E4%BC%98%E5%8C%96%E3%80%82-%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B%E6%9C%AC%E6%96%87%E6%8E%A5%E4%B8%8B%E6%9D%A5%E4%BB%A5%E7%A4%BE%E5%8C%BA%E6%B5%81%E8%A1%8C%E7%9A%84-%E2%80%9Crunwayml-x2F-stable-diffusion-v1-5%E2%80%9D-%E7%9A%84-Text2Img-pipeline-%E4%B8%BA%E4%BE%8B%EF%BC%8C%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D-PAI-Blade-%E5%9C%A8%E5%90%84%E7%B1%BB%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E3%80%82-%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E4%B8%8B%E8%BF%B0%E7%A4%BA%E4%BE%8B%E5%AE%8C%E6%95%B4%E7%9A%84%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC%E5%8F%8A%E7%9B%B8%E5%85%B3%E7%8E%AF%E5%A2%83%E5%B7%B2%E9%9B%86%E6%88%90%E5%88%B0-docker-%E4%B8%AD%E3%80%82%E5%9C%A8%E8%AF%A5docker%E4%B8%AD%EF%BC%8C%E7%9B%B4%E6%8E%A5%E9%80%9A%E8%BF%87-%E5%8D%B3%E5%8F%AF%E8%BF%90%E8%A1%8C%E6%8E%A8%E7%90%86%E7%A4%BA%E4%BE%8B%E3%80%82-%E5%AE%98%E6%96%B9%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E4%BD%BF%E7%94%A8-PAI-Blade-%E4%BC%98%E5%8C%96-Stable-Diffusion-%E6%A8%A1%E5%9E%8B%E5%8F%AF%E4%BB%A5%E5%88%86%E4%B8%BA%E4%BB%A5%E4%B8%8B%E5%87%A0%E4%B8%AA%E6%AD%A5%E9%AA%A4%E3%80%82%E9%A6%96%E5%85%88%EF%BC%8C%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B%E3%80%82-%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%8C%E4%BD%BF%E7%94%A8-PAI-Blade-%E8%BF%9B%E8%A1%8C%E4%BC%98%E5%8C%96%E3%80%82%E6%B3%A8%E6%84%8F%EF%BC%8C%E7%94%B1%E4%BA%8E-PAI-Blade-%E6%98%AF%E5%AE%8C%E5%85%A8%E5%8A%A8%E6%80%81shape%E7%9A%84%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7%EF%BC%8C%E4%BC%98%E5%8C%96%E5%AE%8C%E6%88%90%E5%90%8E%E5%8F%AF%E4%BD%BF%E7%94%A8%E4%BB%BB%E6%84%8Fshape%E8%BF%9B%E8%A1%8C%E6%8E%A8%E7%90%86%E3%80%82-%E6%9C%80%E5%90%8E%EF%BC%8C%E4%BD%BF%E7%94%A8%E4%BC%98%E5%8C%96%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E6%9B%BF%E6%8D%A2%E5%8E%9F%E5%A7%8B%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%90%8E%E7%BB%AD%E5%8D%B3%E5%8F%AF%E4%BB%A5%E5%8E%9F%E5%A7%8B-pipeline-%E5%90%8C%E6%A0%B7%E7%9A%84%E6%96%B9%E5%BC%8F%E8%BF%9B%E8%A1%8C%E6%8E%A8%E7%90%86%E3%80%82-A100-%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94-image-size-samplesteps-Time-of-Pytorch-s-Time-of-PAI-Blade-s-speedup-Pytorch-memory-usage-GB-PAI-Blade-memory-usage-GB-1024x1024-50-13-26-4-34-3-06X-32-91-6-25-768x768-50-5-65-2-00-2-83X-14-99-5-91-512x512-50-2-24-0-84-2-67X-6-60-5-42-A10-%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94-image-size-samplesteps-Time-of-Pytorch-s-Time-of-PAI-Blade-s-speedup-Pytorch-memory-usage-GB-PAI-Blade-memory-usage-GB-1024x1024-50-OOM-13-86"><span class="post-toc-text">AIGC是人工智能计算领域里发展迅速的重要业务。Stable Diffusion 是其中最热门的开源模型���受到广泛关注。然而，随着应用场景不断扩大，Stable Diffusion所面临的推理时延和计算成本问题也越来越突出。### 简介PAI-Blade是 PAI 推出的通用推理优化工具，可以通过模型系统联合优化，使模型达到最优推理性能。PAI-Blade依托于完全动态尺寸的AI编译器BladeDISC 和 基于深度学习自动调度的高性能计算库BlaDNN， 为包括图像生成模型Stable Diffsuion, 大语言模型LLM, 大规模稀疏推荐模型CTR, 语音识别模型ASR等等在内的众多模型提供自动的高性能推理优化。BladeDISC 是一款支持完全动态尺寸的AI编译器，前端支持Pytorch和Tensorflow模型。对于Pytorch模型能够支持 TorchScript 和 TorchDynamo 两种输入模式，后端通过 AStitch 大尺度算子融合技术和高效的 codegen 逻辑提升模型访存密集算子的执行效率。BladeDISC现已在github开源，项目地址：https:&#x2F;&#x2F;github.com&#x2F;alibaba&#x2F;BladeDISC 。BlaDNN 是基于深度学习自动调度的高性能计算库。BlaDNN 作为Ansor的升级版，不仅生成的kernel性能超过Ansor，而且可以完全依赖DNN自动调度而不使用Tuning调优，使得Dynamic Shape业务场景的在线自动调度成为可能，基于DNN自动调度生成的GPU计算密集算子的平均性能达到极致tuning性能的99.39%，通过模型系统联合优化DNN推理延时低至2us, 并且只使用一个CPU Core，从而不会对GPU模型本身的性能造成任何抖动。通过采用 PAI-Blade 加速推理优化技术，对访存密集型算子进行大尺度融合及优化代码生成，对计算密集型算子进行自动调度，可以大幅度降低Stable Diffusion的推理延迟和显存占用，从而减少计算成本。使用 PAI-Blade 优化Stable Diffusion 具有以下三点优势： 高性能，使用Blade可以降低 Text2Img、Img2Img 等推理流程的端到端延迟 2.42-3.05 倍，同时可降低省显存占用至多 5.27 倍，超过TensorRT-8.5等业内SOTA优化手段。 完全动态shape支持，一次优化后，可以支持任意形状、batch size的输入。 易用性、可扩展性：仅需数行代码即可在多类pipeline中启用 Blade优化，同时能支持LoRA等推理方案的优化。### 使用示例本文接下来以社区流行的 “runwayml&#x2F;stable-diffusion-v1-5” 的 Text2Img pipeline 为例，详细介绍 PAI-Blade 在各类使用场景下的使用方法。#### 环境安装下述示例完整的运行脚本及相关环境已集成到 1registry.cn-beijing.aliyuncs.com&#x2F;blade_demo&#x2F;blade_diffusion docker 中。在该docker中，直接通过 1python &#x2F;blade&#x2F;blade_diffusion.py 即可运行推理示例。#### 官方模型优化使用 PAI-Blade 优化 Stable Diffusion 模型可以分为以下几个步骤。首先，加载预训练的模型。 12345 from diffusers import StableDiffusionPipelinedevice &#x3D; torch.device(&quot;cuda:0&quot;)pipe &#x3D; StableDiffusionPipeline.from_pretrained(&quot;runwayml&#x2F;stable-diffusion-v1-5&quot;, revision&#x3D;&quot;fp16&quot;, torch_dtype&#x3D;torch.float16).to(device)第二步，使用 PAI-Blade 进行优化。注意，由于 PAI-Blade 是完全动态shape的优化工具，优化完成后可使用任意shape进行推理。 123456789 import torch_bladeopt_cfg &#x3D; torch_blade.Config()opt_cfg.enable_fp16 &#x3D; Truewith opt_cfg, torch.no_grad(): encoder &#x3D; blade_optimize(pipe.text_encoder, model_inputs&#x3D;encoder_inputs, allow_tracing&#x3D;True) unet &#x3D; blade_optimize(pipe.unet, model_inputs&#x3D;unet_inputs, allow_tracing&#x3D;True) decoder &#x3D; blade_optimize(pipe.vae.decoder, model_inputs&#x3D;decoder_inputs, allow_tracing&#x3D;True)最后，使用优化好的模型替换原始模型，后续即可以原始 pipeline 同样的方式进行推理。 12345678910111213141516171819202122232425262728293031323334 @dataclassclass UNet2DConditionOutput: sample: torch.FloatTensorclass TracedUNet(torch.nn.Module): def __init__(self): super().__init__() self.config &#x3D; pipe.unet.config self.in_channels &#x3D; pipe.unet.in_channels self.device &#x3D; pipe.unet.device def forward(self, latent_model_input, t, encoder_hidden_states, **kwargs): sample &#x3D; unet(latent_model_input.half(), t.half(), encoder_hidden_states.half())[&quot;sample&quot;] return UNet2DConditionOutput(sample&#x3D;sample)class TracedEncoder(torch.nn.Module): def __init__(self): super().__init__() self.config &#x3D; pipe.text_encoder.config self.device &#x3D; pipe.text_encoder.device self.dtype &#x3D; torch.half def forward(self, input_ids, **kwargs): embeddings &#x3D; encoder(input_ids.long()) return [embeddings[&quot;last_hidden_state&quot;]]class TracedDecoder(torch.nn.Module): def forward(self, input): return decoder(input.half())pipe.text_encoder &#x3D; TracedEncoder()pipe.unet &#x3D; TracedUNet()pipe.vae.decoder &#x3D; TracedDecoder()##### A100 性能对比 image size samplesteps Time of Pytorch(s) Time of PAI-Blade(s) speedup Pytorch memory usage (GB) PAI-Blade memory usage (GB) 1024x1024 50 13.26 4.34 3.06X 32.91 6.25 768x768 50 5.65 2.00 2.83X 14.99 5.91 512x512 50 2.24 0.84 2.67X 6.60 5.42##### A10 性能对比 image size samplesteps Time of Pytorch(s) Time of PAI-Blade(s) speedup Pytorch memory usage (GB) PAI-Blade memory usage (GB) 1024x1024 50 OOM 13.86</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#%E6%8E%A8%E7%90%86%E7%BB%93%E6%9E%9C%E9%AA%8C%E8%AF%81"><span class="post-toc-text">推理结果验证</span></a></li></ol></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%B7%B2%E9%AA%8C%E8%AF%81%E7%9A%84pipeline%E7%B1%BB%E5%9E%8B"><span class="post-toc-text">已验证的pipeline类型</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#LoRA%E4%BC%98%E5%8C%96"><span class="post-toc-text">LoRA优化</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%B1%95%E6%9C%9B"><span class="post-toc-text">展望</span></a></li></nav></aside><nav id="article-nav"><a href="/54ac5fe3/" id="article-nav-newer" class="article-nav-link-wrap"><span class="article-nav-title"><i class="fa fa-hand-o-left" aria-hidden="true"></i> 推荐系列-京东购物车如何提升30%性能 - 京东云技术团队 </span></a><a href="/e014a9ec/" id="article-nav-older" class="article-nav-link-wrap"><span class="article-nav-title">推荐系列-共话开源，为热爱而聚！2023开放原子全球开源峰会-开发者之夜-节目征集进行中！</span> <i class="fa fa-hand-o-right" aria-hidden="true"></i></a></nav><div id="gitalk"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script>var gitalk=new Gitalk({repo:"bolg-comment",owner:"Hosiang1026",admin:"Hosiang1026",clientID:"37a2dd4473e8970cecc2",clientSecret:"e30efa17d86d9de4f4ab810872dc62a7b2e7e634",pagerDirection:"last",distractionFreeMode:!0,createIssueManually:!1});gitalk.render("gitalk")</script></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner"><script id="_wau78w">var _wau=_wau||[];_wau.push(["small","5dnguv4c2n","78w"])</script><script async src="//waust.at/s.js"></script><p><span id="busuanzi_container_site_uv" style="display:none"><span class="post-count">总字数：<span>1841.6k</span> </span>总访客数：<span id="busuanzi_value_site_uv"></span> </span><span id="busuanzi_container_site_pv" style="display:none">总访问量：<span id="busuanzi_value_site_pv"></span></span><br><span id="TimeShow">本站</span><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><br>Copyright&copy; 2018 - 2023 狂欢马克思 <a href="https://beian.miit.gov.cn" rel="external nofollow noopener noreferrer" target="_blank">京ICP备17060439号</a></p></div></div><script>var now=new Date;function createtime(){var n=new Date("2017/09/18");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="安全运行 "+dnum+" 天 ",document.getElementById("times").innerHTML=hnum+" 小时 "+mnum+" 分 "+snum+" 秒"}setInterval("createtime()",800)</script></footer><script>var mihoConfig={root:"https://haoxiang.eu.org",animate:"true",isHome:"false",share:"true",reward:" 1"}</script><div class="sidebar"><div id="sidebar-search" title="Search"><i class="fa fa-search"></i></div><div id="sidebar-category" title="Categories"><i class="fa fa-book"></i></div><div id="sidebar-tag" title="Tags"><i class="fa fa-tags"></i></div><div id="sidebar-top"><span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span></div></div><div class="sidebar-menu-box" id="sidebar-menu-box"><div class="sidebar-menu-box-container"><div id="sidebar-menu-box-categories"><a class="category-link" href="/categories/%E5%85%B4%E8%B6%A3%E7%88%B1%E5%A5%BD/">兴趣爱好</a><a class="category-link" href="/categories/%E5%85%B6%E4%BB%96%E5%BC%80%E5%8F%91/">其他开发</a><a class="category-link" href="/categories/%E5%89%8D%E6%B2%BF%E5%BC%80%E5%8F%91/">前沿开发</a><a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/">前端开发</a><a class="category-link" href="/categories/%E5%8D%87%E7%BA%A7%E7%89%88%E6%9C%AC/">升级版本</a><a class="category-link" href="/categories/%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B/">博客教程</a><a class="category-link" href="/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/">后端开发</a><a class="category-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a><a class="category-link" href="/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/">日常记录</a><a class="category-link" href="/categories/%E7%83%AD%E9%97%A8%E6%96%87%E7%AB%A0/">热门文章</a></div><div id="sidebar-menu-box-tags"><a href="/tags/Ajax/" style="font-size:10px">Ajax</a> <a href="/tags/AliGenie/" style="font-size:10px">AliGenie</a> <a href="/tags/Alipay/" style="font-size:10px">Alipay</a> <a href="/tags/Android/" style="font-size:10px">Android</a> <a href="/tags/Blockchain/" style="font-size:17.5px">Blockchain</a> <a href="/tags/CQRS/" style="font-size:10px">CQRS</a> <a href="/tags/Database/" style="font-size:15px">Database</a> <a href="/tags/Docker/" style="font-size:10px">Docker</a> <a href="/tags/EasyUI/" style="font-size:10px">EasyUI</a> <a href="/tags/Guitar/" style="font-size:10px">Guitar</a> <a href="/tags/Hackintosh/" style="font-size:12.5px">Hackintosh</a> <a href="/tags/Hexo/" style="font-size:15px">Hexo</a> <a href="/tags/IntelliJ-IDEA/" style="font-size:10px">IntelliJ IDEA</a> <a href="/tags/Java/" style="font-size:12.5px">Java</a> <a href="/tags/Kali-Linux/" style="font-size:10px">Kali Linux</a> <a href="/tags/Life/" style="font-size:17.5px">Life</a> <a href="/tags/Mac-OS/" style="font-size:12.5px">Mac OS</a> <a href="/tags/MultiThread/" style="font-size:10px">MultiThread</a> <a href="/tags/NAS/" style="font-size:10px">NAS</a> <a href="/tags/NodeJS/" style="font-size:10px">NodeJS</a> <a href="/tags/Popular/" style="font-size:20px">Popular</a> <a href="/tags/Python/" style="font-size:10px">Python</a> <a href="/tags/SaaS/" style="font-size:10px">SaaS</a> <a href="/tags/Servlet/" style="font-size:10px">Servlet</a> <a href="/tags/Spring/" style="font-size:17.5px">Spring</a> <a href="/tags/System/" style="font-size:10px">System</a> <a href="/tags/Upgrade/" style="font-size:10px">Upgrade</a> <a href="/tags/Web/" style="font-size:10px">Web</a> <a href="/tags/Windows/" style="font-size:10px">Windows</a> <a href="/tags/Work/" style="font-size:10px">Work</a> <a href="/tags/iOS/" style="font-size:10px">iOS</a></div></div><a href="javascript:" class="sidebar-menu-box-close">&times;</a></div><div class="mobile-header-menu-nav" id="mobile-header-menu-nav"><div class="mobile-header-menu-container"><span class="title">导航</span><ul class="mobile-header-menu-navbar"><li><a href="/"><i class="fa fa-home"></i><span>主页</span></a></li><li><a href="/archives"><i class="fa fa-archive"></i><span>归档</span></a></li><li><a href="/gitbook"><i class="fa fa-columns"></i><span>笔记</span></a></li><li><a href="/photo"><i class="fa fa-picture-o"></i><span>相册</span></a></li><li><a href="/love"><i class="fa fa-heart"></i><span>恋爱</span></a></li><li><a href="/collection"><i class="fa fa-envira"></i><span>收藏</span></a></li><li><a href="/about"><i class="fa fa-user"></i><span>关于</span></a></li></ul></div><div class="mobile-header-tag-container"><span class="title">标签</span><div id="mobile-header-container-tags"><a href="/tags/Ajax/" style="font-size:10px">Ajax</a> <a href="/tags/AliGenie/" style="font-size:10px">AliGenie</a> <a href="/tags/Alipay/" style="font-size:10px">Alipay</a> <a href="/tags/Android/" style="font-size:10px">Android</a> <a href="/tags/Blockchain/" style="font-size:17.5px">Blockchain</a> <a href="/tags/CQRS/" style="font-size:10px">CQRS</a> <a href="/tags/Database/" style="font-size:15px">Database</a> <a href="/tags/Docker/" style="font-size:10px">Docker</a> <a href="/tags/EasyUI/" style="font-size:10px">EasyUI</a> <a href="/tags/Guitar/" style="font-size:10px">Guitar</a> <a href="/tags/Hackintosh/" style="font-size:12.5px">Hackintosh</a> <a href="/tags/Hexo/" style="font-size:15px">Hexo</a> <a href="/tags/IntelliJ-IDEA/" style="font-size:10px">IntelliJ IDEA</a> <a href="/tags/Java/" style="font-size:12.5px">Java</a> <a href="/tags/Kali-Linux/" style="font-size:10px">Kali Linux</a> <a href="/tags/Life/" style="font-size:17.5px">Life</a> <a href="/tags/Mac-OS/" style="font-size:12.5px">Mac OS</a> <a href="/tags/MultiThread/" style="font-size:10px">MultiThread</a> <a href="/tags/NAS/" style="font-size:10px">NAS</a> <a href="/tags/NodeJS/" style="font-size:10px">NodeJS</a> <a href="/tags/Popular/" style="font-size:20px">Popular</a> <a href="/tags/Python/" style="font-size:10px">Python</a> <a href="/tags/SaaS/" style="font-size:10px">SaaS</a> <a href="/tags/Servlet/" style="font-size:10px">Servlet</a> <a href="/tags/Spring/" style="font-size:17.5px">Spring</a> <a href="/tags/System/" style="font-size:10px">System</a> <a href="/tags/Upgrade/" style="font-size:10px">Upgrade</a> <a href="/tags/Web/" style="font-size:10px">Web</a> <a href="/tags/Windows/" style="font-size:10px">Windows</a> <a href="/tags/Work/" style="font-size:10px">Work</a> <a href="/tags/iOS/" style="font-size:10px">iOS</a></div></div></div><div class="search-wrap"><span class="search-close">&times;</span> <a href="javascript:" class="header-icon waves-effect waves-circle waves-light" id="back"><i class="icon icon-lg icon-chevron-left"></i> </a><input class="search-field" placeholder="Search..." id="keywords"> <a id="search-submit" href="javascript:"><i class="fa fa-search"></i></a><div class="search-container" id="search-container"><ul class="search-result" id="search-result"></ul></div></div><div id="search-tpl"><li class="search-result-item"><a href="{url}" class="search-item-li"><span class="search-item-li-title" title="{title}">{title}</span></a></li></div><script src="/js/search.js"></script><script src="/js/main.js"></script><script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script><div id="particles"></div><script src="/js/particles.js"></script><link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css"><script src="//cdn.bootcss.com/scrollReveal.js/3.0.5/scrollreveal.js"></script><script src="/js/animate.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{jsonPath:"/live2dw/assets/hijiki.model.json"},display:{position:"right",width:150,height:300},mobile:{show:!0,scale:.5},log:!1})</script></body></html>