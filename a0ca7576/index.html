<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="Access-Control-Allow-Origin" content="*"><script type="text/javascript">var start_time=(new Date).getTime()</script><meta http-equiv="Cache-Control" content="no-cache"><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="viewport" content="initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="google-site-verification" content="9Wt3lmnrT2bfjaHla5s16adhvcQcBHO7PtNf97n5Od0"><meta name="baidu-site-verification" content="RYlYHsgO7Y"><meta name="sogou_site_verification" content="MSmrTj7lHV"><meta name="shenma-site-verification" content="e4428ccce0f22fad61c3716193bf4bd7_1571416388"><meta name="baidu_union_verify" content="584bb6b4bd24108df082b6d20c7aa9be"><title>推荐系列-DL4J之CNN对今日头条文本分类 | 狂欢马克思</title><meta name="keywords" content="分享技术经验与交流"><meta name="description" content="&amp;emsp;&amp;emsp;一、数据集介绍 数据来源：今日头条客户端 数据格式如下： 6551700932705387022_!101!_news_culture_!京城最值得你来场文化之旅的博物馆!_保利集团,马未都,中国科学技术馆,博物馆,新中国…"><meta property="og:type" content="article"><meta property="og:title" content="推荐系列-DL4J之CNN对今日头条文本分类"><meta property="og:url" content="https://www.hosiang.cn/a0ca7576/index.html"><meta property="og:site_name" content="狂欢马克思"><meta property="og:description" content="&amp;emsp;&amp;emsp;一、数据集介绍 数据来源：今日头条客户端 数据格式如下： 6551700932705387022_!101!_news_culture_!京城最值得你来场文化之旅的博物馆!_保利集团,马未都,中国科学技术馆,博物馆,新中国…"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://oscimg.oschina.net/oscnet/c943ed94cdf1c2572c9a16245ff8b781d60.jpg"><meta property="og:image" content="https://oscimg.oschina.net/oscnet/c943ed94cdf1c2572c9a16245ff8b781d60.jpg"><meta property="og:image" content="https://oscimg.oschina.net/oscnet/c943ed94cdf1c2572c9a16245ff8b781d60.jpg"><meta property="og:image" content="https://oscimg.oschina.net/oscnet/c943ed94cdf1c2572c9a16245ff8b781d60.jpg"><meta property="og:image" content="https://oscimg.oschina.net/oscnet/c943ed94cdf1c2572c9a16245ff8b781d60.jpg"><meta property="article:published_time" content="2021-04-15T01:19:21.000Z"><meta property="article:modified_time" content="2022-03-27T01:29:07.600Z"><meta property="article:author" content="Howe Hsiang"><meta property="article:tag" content="Popular"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://oscimg.oschina.net/oscnet/c943ed94cdf1c2572c9a16245ff8b781d60.jpg"><link rel="icon" href="/images/favicon.ico"><link href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"><link href="https://cdn.bootcss.com/font-awesome-animation/0.1.0/font-awesome-animation.min.css" rel="stylesheet"><link rel="stylesheet" href="/css/style.css"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?3cd8fa109426bf3f10bd5c362175bace";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script></script><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta name="generator" content="Hexo 5.4.1"></head><script src="/js/jquery.min.js"></script><script src="/js/pace.min.js"></script><script src="/js/crypto-js.js"></script><script src="/js/cookie.js"></script><script src="/js/calendar.js"></script><script src="/js/festival.js"></script><script>getFestival()</script><body><script>window.onload=function(){document.getElementById("TimeShow").innerHTML="本站耗时 "+((new Date).getTime()-start_time)/1e3+" 秒 "}</script><div id="container"><header id="header"><div id="banner"></div><div id="header-outer"><div id="header-menu" class="header-menu-pos animated"><div class="header-menu-container"><a href="/" class="left"><span class="site-title">狂欢马克思</span></a><nav id="header-menu-nav" class="right"><a href="/" rel="external nofollow"><i class="fa fa-home"></i> <span>主页</span> </a><a href="/archives" rel="external nofollow"><i class="fa fa-archive"></i> <span>归档</span> </a><a href="/gitbook" rel="external nofollow"><i class="fa fa-columns"></i> <span>笔记</span> </a><a href="/music" rel="external nofollow"><i class="fa fa-music"></i> <span>音乐</span> </a><a href="/photo" rel="external nofollow"><i class="fa fa-picture-o"></i> <span>相册</span> </a><a href="/collection" rel="external nofollow"><i class="fa fa-envira"></i> <span>收藏</span> </a><a href="/about" rel="external nofollow"><i class="fa fa-user"></i> <span>关于</span></a></nav><a class="mobile-header-menu-button"><i class="fa fa-bars"></i></a></div></div><div id="header-row"><div id="logo"><a href="/"><img src="/../images/logo.png" alt="logo"></a></div><div class="header-info"><div id="header-title"><h2>狂欢马克思</h2></div><div id="header-description"><h3>专注Web开发</h3></div></div><nav class="header-nav"><div class="social"><a title="Github" target="_blank" href="//github.com/Hosiang1026" rel="external nofollow"><i class="fa fa-github fa-2x"></i></a> <a title="QQ" target="_blank" href="//wpa.qq.com/msgrd?v=3&uin=641904695&site=qq&menu=yes" rel="external nofollow"><i class="fa fa-qq fa-2x"></i></a> <a title="Weibo" target="_blank" href="//www.weibo.com/haoxiang969" rel="external nofollow"><i class="fa fa-weibo fa-2x"></i></a></div></nav></div><div id="noticeId" class="show" style="background:rgb(244,247,247,.3)"><marquee id="noticeMar" behavior="scoll" class="notice" direction="left" onmouseover="this.stop()" onmouseout="this.start()"></marquee></div><script type="text/javascript">function browserRedirect(){var i=navigator.userAgent.toLowerCase(),n="ipad"==i.match(/ipad/i),o="iphone os"==i.match(/iphone os/i),a="midp"==i.match(/midp/i),t="rv:1.2.3.4"==i.match(/rv:1.2.3.4/i),e="ucweb"==i.match(/ucweb/i),s="android"==i.match(/android/i),d="windows ce"==i.match(/windows ce/i),p="windows mobile"==i.match(/windows mobile/i),r="",c=randomColor(),r=n||o||a||t||e||s||d||p?($("#noticeId").css({"line-height":"1.6em"}),"<font style='color:"+c+"' face='新华宋体'  size='2'>官宣：<span id='weekend'></span><span id='msg'></span><span id='timer'></span><span id='hitokoto'></span></span></span><span id='YQData'></font> "):($("#noticeId").css({"line-height":"3.6em","margin-top":"20px"}),"<font style='color:"+c+"' face='新华宋体'  size='6'>官宣：<span id='weekend'></span><span id='msg'></span><span id='timer'></span><span id='hitokoto'></span></span><span id='YQData'></span></font> ");$("#noticeMar").html(r)}function randomColor(){for(var i="0,1,2,3,4,5,6,7,8,9,a,b,c,d,e,f".split(","),n="#",o=0;o<6;o++)n+=i[Math.floor(16*Math.random())];return n}$(function(){browserRedirect(),0<$("#hitokoto").length&&getHitokoto()})</script></div></header><script>console.log=function(){}</script><div class="outer"><section id="main" class="body-wrap"><article id="post-DL4J之CNN对今日头条文本分类" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 class="post-title" itemprop="name">推荐系列-DL4J之CNN对今日头条文本分类</h1><div class="post-title-bar"><ul><li><i class="fa fa-book"></i> <a href="/categories/热门文章/">热门文章</a></li><li><i class="fa fa-calendar"></i> 2021-04-15</li><li><i class="fa fa-eye"></i> <span id="busuanzi_value_page_pv"></span></li><li><span class="post-count">字数统计: 3.5k字</span></li><li><span class="post-count">阅读时长: 17分钟</span></li></ul></div></header><div class="article-entry post-content" itemprop="articleBody"><p>&emsp;&emsp;一、数据集介绍 数据来源：今日头条客户端 数据格式如下： 6551700932705387022_!<em>101</em>!_news_culture_!<em>京城最值得你来场文化之旅的博物馆</em>!_保利集团,马未都,中国科学技术馆,博物馆,新中国…<br><span id="more"></span></p><pre><code>                                                                                                                                                                                    一、数据集介绍 
数据来源：今日头条客户端 
数据格式如下： 
</code></pre><pre><code class="java">  <span class="number">6551700932705387022</span>_!_101_!_news_culture_!_京城最值得你来场文化之旅的博物馆_!_保利集团,马未都,中国科学技术馆,博物馆,新中国
<span class="number">6552368441838272771</span>_!_101_!_news_culture_!_发酵床的垫料种类有哪些？哪种更好？_!_
<span class="number">6552407965343678723</span>_!_101_!_news_culture_!_上联：黄山黄河黄皮肤黄土高原。怎么对下联？_!_
<span class="number">6552332417753940238</span>_!_101_!_news_culture_!_林徽因什么理由拒绝了徐志摩而选择梁思成为终身伴侣？_!_
<span class="number">6552475601595269390</span>_!_101_!_news_culture_!_黄杨木是什么树？_!_
</code></pre><pre><code>每行为一条数据，以_!_分割的个字段，从前往后分别是 新闻ID，分类code（见下文），分类名称（见下文），新闻字符串（仅含标题），新闻关键词 
分类code与名称： 
</code></pre><pre><code class="java">  <span class="number">100</span> 民生 故事 news_story
<span class="number">101</span> 文化 文化 news_culture
<span class="number">102</span> 娱乐 娱乐 news_entertainment
<span class="number">103</span> 体育 体育 news_sports
<span class="number">104</span> 财经 财经 news_finance
<span class="number">106</span> 房产 房产 news_house
<span class="number">107</span> 汽车 汽车 news_car
<span class="number">108</span> 教育 教育 news_edu 
<span class="number">109</span> 科技 科技 news_tech
<span class="number">110</span> 军事 军事 news_military
<span class="number">112</span> 旅游 旅游 news_travel
<span class="number">113</span> 国际 国际 news_world
<span class="number">114</span> 证券 股票 stock
<span class="number">115</span> 农业 三农 news_agriculture
<span class="number">116</span> 电竞 游戏 news_game
</code></pre><pre><code>github地址：https://github.com/fate233/toutiao-text-classfication-dataset 
数据资源中给出了分类的实验结果： 
</code></pre><pre><code class="java">  Test Loss:   <span class="number">0.57</span>, Test Acc:  <span class="number">83.81</span>%

                    precision    recall  f1-score   support

        news_story       <span class="number">0.66</span>      <span class="number">0.75</span>      <span class="number">0.70</span>       <span class="number">848</span>

      news_culture       <span class="number">0.57</span>      <span class="number">0.83</span>      <span class="number">0.68</span>      <span class="number">1531</span>

news_entertainment       <span class="number">0.86</span>      <span class="number">0.86</span>      <span class="number">0.86</span>      <span class="number">8078</span>

       news_sports       <span class="number">0.94</span>      <span class="number">0.91</span>      <span class="number">0.92</span>      <span class="number">7338</span>

      news_finance       <span class="number">0.59</span>      <span class="number">0.67</span>      <span class="number">0.63</span>      <span class="number">1594</span>

        news_house       <span class="number">0.84</span>      <span class="number">0.89</span>      <span class="number">0.87</span>      <span class="number">1478</span>

          news_car       <span class="number">0.92</span>      <span class="number">0.90</span>      <span class="number">0.91</span>      <span class="number">6481</span>

          news_edu       <span class="number">0.71</span>      <span class="number">0.86</span>      <span class="number">0.77</span>      <span class="number">1425</span>

         news_tech       <span class="number">0.85</span>      <span class="number">0.84</span>      <span class="number">0.85</span>      <span class="number">6944</span>

     news_military       <span class="number">0.90</span>      <span class="number">0.78</span>      <span class="number">0.84</span>      <span class="number">6174</span>

       news_travel       <span class="number">0.58</span>      <span class="number">0.76</span>      <span class="number">0.66</span>      <span class="number">1287</span>

        news_world       <span class="number">0.72</span>      <span class="number">0.69</span>      <span class="number">0.70</span>      <span class="number">3823</span>

             stock       <span class="number">0.00</span>      <span class="number">0.00</span>      <span class="number">0.00</span>        <span class="number">53</span>

  news_agriculture       <span class="number">0.80</span>      <span class="number">0.88</span>      <span class="number">0.84</span>      <span class="number">1701</span>

         news_game       <span class="number">0.92</span>      <span class="number">0.87</span>      <span class="number">0.89</span>      <span class="number">6244</span>

       avg / total       <span class="number">0.85</span>      <span class="number">0.84</span>      <span class="number">0.84</span>     <span class="number">54999</span>

</code></pre><p>下面我们就来用deeplearning4j来实现一个卷积结构对该数据集进行分类，看能不能得到更好的结果。<br>二、卷积网络可以用于文本处理的原因<br>CNN非常适合处理图像数据，前面一篇文章《deeplearning4j——卷积神经网络对验证码进行识别》介绍了CNN对验证码进行识别。本篇博客将利用CNN对文本进行分类，在开始之前我们先来直观的说说卷积运算在做的本质事情是什么。卷积运算，本质上可以看做两个向量的点积，两个向量越同向，点积就越大，经过relu和MaxPooling之后，本质上是提取了与卷积核最同向的结构，这个“结构”实际上是图片上的一些线条。<br>那么文本可以用CNN来处理吗？答案是肯定的，文本每个词用向量表示之后，依次排开，就变成了一张二维图，如下图，沿着红色箭头的方向（也就是文本的方向）看，两个句子用一幅图表示之后，会出现相同的单元，也就可以用CNN来处理。<br><img src="https://oscimg.oschina.net/oscnet/c943ed94cdf1c2572c9a16245ff8b781d60.jpg" alt="Test" title="DL4J之CNN对今日头条文本分类"><br>三、文本处理的卷积结构<br>那么，怎么设计这个CNN网络结构呢？如下图：（论文地址：<a target="_blank" rel="external nofollow noopener noreferrer" href="https://arxiv.org/abs/1408.5882）">https://arxiv.org/abs/1408.5882）</a><br><img src="https://oscimg.oschina.net/oscnet/c943ed94cdf1c2572c9a16245ff8b781d60.jpg" alt="Test" title="DL4J之CNN对今日头条文本分类"><br>注意点：<br>1、卷积核移动的方向必须为句子的方向<br>2、每个卷积核提取的特征为N行1列的向量<br>3、MaxPooling的操作的对象是每一个Feature Map，也就是从每一个N行1列的向量中选择一个最大值<br>4、把选择的所有最大值接起来，经过几个Fully Connected 层，进行分类<br>四、数据的预处理与词向量<br>1、分词工具：HanLP<br>2、处理后的数据格式如下：（类别code_!<em>词，其中，词与词之间用空格隔开，</em>!_为分割符）<br><img src="https://oscimg.oschina.net/oscnet/c943ed94cdf1c2572c9a16245ff8b781d60.jpg" alt="Test" title="DL4J之CNN对今日头条文本分类"><br>数据预处理代码如下：</p><pre><code class="java"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;
      BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(
              <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"/toutiao_cat_data/toutiao_cat_data.txt"</span>)), <span class="string">"UTF-8"</span>));
      OutputStreamWriter writerStream = <span class="keyword">new</span> OutputStreamWriter(
              <span class="keyword">new</span> FileOutputStream(<span class="string">"/toutiao_cat_data/toutiao_data_type_word.txt"</span>), <span class="string">"UTF-8"</span>);
      BufferedWriter writer = <span class="keyword">new</span> BufferedWriter(writerStream);
      String line = <span class="keyword">null</span>;
      <span class="keyword">long</span> startTime = System.currentTimeMillis();
      <span class="keyword">while</span> ((line = bufferedReader.readLine()) != <span class="keyword">null</span>) &#123;
          String[] array = line.split(<span class="string">"_!_"</span>);
          StringBuilder stringBuilder = <span class="keyword">new</span> StringBuilder();
          <span class="keyword">for</span> (Term term : HanLP.segment(array[<span class="number">3</span>])) &#123;
              <span class="keyword">if</span> (stringBuilder.length() &gt; <span class="number">0</span>) &#123;
                  stringBuilder.append(<span class="string">" "</span>);
              &#125;
              stringBuilder.append(term.word.trim());
          &#125;
          writer.write(Integer.parseInt(array[<span class="number">1</span>].trim()) + <span class="string">"_!_"</span> + stringBuilder.toString() + <span class="string">"\n"</span>);
      &#125;
      writer.flush();
      writer.close();
      System.out.println(System.currentTimeMillis() - startTime);
      bufferedReader.close();
  &#125;
</code></pre><p>五、词的向量表示<br>1、one-hot<br>用正交的向量来表示每一个词，这样表示无法反应词与词之间的关系，那么两句话中，要想复用同一个卷积核，那么必须出现一模一样的词才可以，实际上，我们要求模型可以举一反三，连相似的结构也可以提取，那么word2vec可以解决这个问题。<br>2、word2vec<br>word2vec可以充分考虑词与词之间的关系，相似的词，肯定有某些维度靠的比较近。那么也就考虑了词的语句之间的���系，训练word2vec有两种，skipgram和cbow，下面我们用cbow来训练词向量，结果会持久化下来，就得到了toutiao.vec的文件，下次变可重新加载该文件获得词的向量表示，代码如下：</p><pre><code class="java">String filePath = <span class="keyword">new</span> ClassPathResource(<span class="string">"toutiao_data_word.txt"</span>).getFile().getAbsolutePath();
      SentenceIterator iter = <span class="keyword">new</span> BasicLineIterator(filePath);
      TokenizerFactory t = <span class="keyword">new</span> DefaultTokenizerFactory();
      t.setTokenPreProcessor(<span class="keyword">new</span> CommonPreprocessor());
      VocabCache&lt;VocabWord&gt; cache = <span class="keyword">new</span> AbstractCache&lt;&gt;();
      WeightLookupTable&lt;VocabWord&gt; table = <span class="keyword">new</span> InMemoryLookupTable.Builder&lt;VocabWord&gt;().vectorLength(<span class="number">100</span>)
              .useAdaGrad(<span class="keyword">false</span>).cache(cache).build();

      log.info(<span class="string">"Building model...."</span>);
      Word2Vec vec = <span class="keyword">new</span> Word2Vec.Builder()
              .elementsLearningAlgorithm(<span class="string">"org.deeplearning4j.models.embeddings.learning.impl.elements.CBOW"</span>)
              .minWordFrequency(<span class="number">0</span>).iterations(<span class="number">1</span>).epochs(<span class="number">20</span>).layerSize(<span class="number">100</span>).seed(<span class="number">42</span>).windowSize(<span class="number">8</span>).iterate(iter)
              .tokenizerFactory(t).lookupTable(table).vocabCache(cache).build();

      vec.fit();
      WordVectorSerializer.writeWord2VecModel(vec, <span class="string">"/toutiao_cat_data/toutiao.vec"</span>);
</code></pre><p>六、CNN网络结构<br>CNN网络结构如下：<br><img src="https://oscimg.oschina.net/oscnet/c943ed94cdf1c2572c9a16245ff8b781d60.jpg" alt="Test" title="DL4J之CNN对今日头条文本分类"><br>说明：<br>1、cnn3、cnn4、cnn5、cnn6卷积核大小为（3，vectorSize）、（4，vectorSize）、（5，vectorSize）、（6，vectorSize），步幅为1，也就是分别读取3、4、5、6个词，提取特征<br>2、cnn3-stride2、cnn4-stride2、cnn5-stride2、cnn6-stride2卷积核大小为（3，vectorSize）、（4，vectorSize）、（5，vectorSize）、（6，vectorSize）,步幅为2<br>3、两组卷积核卷积的结果合并，分别得到merge1和merge2，都是4维张量，形状分别为（batchSize，depth1+depth2+depth3，height/1,1），（batchSize，depth1+depth2+depth3，height/2,1），特别说明：这里的卷积模式为ConvolutionMode.Same<br>4、merge1、2分别经过MaxPooling，这里用的是GlobalPoolingLayer，和平台的Pooling层不同，这里会从指定维度中，取一个最大值，所以经过GlobalPoolingLayer之后，merge1、2分别变成2维张量，形状为（batchSize，depth1+depth2+depth3），那么GlobalPoolingLayer是如何求Max的呢？源码如下：</p><pre><code class="java"><span class="function"><span class="keyword">private</span> INDArray <span class="title">activateHelperFullArray</span><span class="params">(INDArray inputArray, <span class="keyword">int</span>[] poolDim)</span> </span>&#123;
      <span class="keyword">switch</span> (poolingType) &#123;
          <span class="keyword">case</span> MAX:
              <span class="keyword">return</span> inputArray.max(poolDim);
          <span class="keyword">case</span> AVG:
              <span class="keyword">return</span> inputArray.mean(poolDim);
          <span class="keyword">case</span> SUM:
              <span class="keyword">return</span> inputArray.sum(poolDim);
          <span class="keyword">case</span> PNORM:
              <span class="comment">//P norm: https://arxiv.org/pdf/1311.1780.pdf</span>
              <span class="comment">//out = (1/N * sum( |in| ^ p) ) ^ (1/p)</span>
              <span class="keyword">int</span> pnorm = layerConf().getPnorm();

              INDArray abs = Transforms.abs(inputArray, <span class="keyword">true</span>);
              Transforms.pow(abs, pnorm, <span class="keyword">false</span>);
              INDArray pNorm = abs.sum(poolDim);

              <span class="keyword">return</span> Transforms.pow(pNorm, <span class="number">1.0</span> / pnorm, <span class="keyword">false</span>);
          <span class="keyword">default</span>:
              <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Unknown or not supported pooling type: "</span> + poolingType + <span class="string">" "</span> + layerId());
      &#125;
  &#125;
</code></pre><pre><code>5、两边GlobalPoolingLayer结果再接起来，丢给全连接网络，经过softmax分类器进行分类 
6、fc层，用了0.5的dropout防止过拟合，在下面的代码中可以看到。 
</code></pre><p>完整代码如下：</p><pre><code class="java">  <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CnnSentenceClassificationTouTiao</span> </span>&#123;

    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;

        List&lt;String&gt; trainLabelList = <span class="keyword">new</span> ArrayList&lt;&gt;();<span class="comment">// 训练集label</span>
        List&lt;String&gt; trainSentences = <span class="keyword">new</span> ArrayList&lt;&gt;();<span class="comment">// 训练��文本集合</span>
        List&lt;String&gt; testLabelList = <span class="keyword">new</span> ArrayList&lt;&gt;();<span class="comment">// 测试集label</span>
        List&lt;String&gt; testSentences = <span class="keyword">new</span> ArrayList&lt;&gt;();<span class="comment">//// 测试集文本集合</span>
        Map&lt;String, List&lt;String&gt;&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();

        BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(
                <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"/toutiao_cat_data/toutiao_data_type_word.txt"</span>)), <span class="string">"UTF-8"</span>));
        String line = <span class="keyword">null</span>;
        <span class="keyword">int</span> truncateReviewsToLength = <span class="number">0</span>;
        Random random = <span class="keyword">new</span> Random(<span class="number">123</span>);
        <span class="keyword">while</span> ((line = bufferedReader.readLine()) != <span class="keyword">null</span>) &#123;
            String[] array = line.split(<span class="string">"_!_"</span>);
            <span class="keyword">if</span> (map.get(array[<span class="number">0</span>]) == <span class="keyword">null</span>) &#123;
                map.put(array[<span class="number">0</span>], <span class="keyword">new</span> ArrayList&lt;String&gt;());
            &#125;
            map.get(array[<span class="number">0</span>]).add(array[<span class="number">1</span>]);<span class="comment">// 将样本中所有数据，按照类别归类</span>
            <span class="keyword">int</span> length = array[<span class="number">1</span>].split(<span class="string">" "</span>).length;
            <span class="keyword">if</span> (length &gt; truncateReviewsToLength) &#123;
                truncateReviewsToLength = length;<span class="comment">// 求样本中，句子的最大长度</span>
            &#125;
        &#125;
        bufferedReader.close();
        <span class="keyword">for</span> (Map.Entry&lt;String, List&lt;String&gt;&gt; entry : map.entrySet()) &#123;
            <span class="keyword">for</span> (String sentence : entry.getValue()) &#123;
                <span class="keyword">if</span> (random.nextInt() % <span class="number">5</span> == <span class="number">0</span>) &#123;<span class="comment">// 每个类别抽取20%作为test集</span>
                    testLabelList.add(entry.getKey());
                    testSentences.add(sentence);
                &#125; <span class="keyword">else</span> &#123;
                    trainLabelList.add(entry.getKey());
                    trainSentences.add(sentence);
                &#125;
            &#125;

        &#125;
        <span class="keyword">int</span> batchSize = <span class="number">64</span>;
        <span class="keyword">int</span> vectorSize = <span class="number">100</span>;
        <span class="keyword">int</span> nEpochs = <span class="number">10</span>;

        <span class="keyword">int</span> cnnLayerFeatureMaps = <span class="number">50</span>;
        PoolingType globalPoolingType = PoolingType.MAX;
        Random rng = <span class="keyword">new</span> Random(<span class="number">12345</span>);
        Nd4j.getMemoryManager().setAutoGcWindow(<span class="number">5000</span>);

        ComputationGraphConfiguration config = <span class="keyword">new</span> NeuralNetConfiguration.Builder().weightInit(WeightInit.RELU)
                .activation(Activation.LEAKYRELU).updater(<span class="keyword">new</span> Nesterovs(<span class="number">0.01</span>, <span class="number">0.9</span>))
                .convolutionMode(ConvolutionMode.Same).l2(<span class="number">0.0001</span>).graphBuilder().addInputs(<span class="string">"input"</span>)
                .addLayer(<span class="string">"cnn3"</span>,
                        <span class="keyword">new</span> ConvolutionLayer.Builder().kernelSize(<span class="number">3</span>, vectorSize).stride(<span class="number">1</span>, vectorSize)
                                .nOut(cnnLayerFeatureMaps).build(),
                        <span class="string">"input"</span>)
                .addLayer(<span class="string">"cnn4"</span>,
                        <span class="keyword">new</span> ConvolutionLayer.Builder().kernelSize(<span class="number">4</span>, vectorSize).stride(<span class="number">1</span>, vectorSize)
                                .nOut(cnnLayerFeatureMaps).build(),
                        <span class="string">"input"</span>)
                .addLayer(<span class="string">"cnn5"</span>,
                        <span class="keyword">new</span> ConvolutionLayer.Builder().kernelSize(<span class="number">5</span>, vectorSize).stride(<span class="number">1</span>, vectorSize)
                                .nOut(cnnLayerFeatureMaps).build(),
                        <span class="string">"input"</span>)
                .addLayer(<span class="string">"cnn6"</span>,
                        <span class="keyword">new</span> ConvolutionLayer.Builder().kernelSize(<span class="number">6</span>, vectorSize).stride(<span class="number">1</span>, vectorSize)
                                .nOut(cnnLayerFeatureMaps).build(),
                        <span class="string">"input"</span>)
                .addLayer(<span class="string">"cnn3-stride2"</span>,
                        <span class="keyword">new</span> ConvolutionLayer.Builder().kernelSize(<span class="number">3</span>, vectorSize).stride(<span class="number">2</span>, vectorSize)
                                .nOut(cnnLayerFeatureMaps).build(),
                        <span class="string">"input"</span>)
                .addLayer(<span class="string">"cnn4-stride2"</span>,
                        <span class="keyword">new</span> ConvolutionLayer.Builder().kernelSize(<span class="number">4</span>, vectorSize).stride(<span class="number">2</span>, vectorSize)
                                .nOut(cnnLayerFeatureMaps).build(),
                        <span class="string">"input"</span>)
                .addLayer(<span class="string">"cnn5-stride2"</span>,
                        <span class="keyword">new</span> ConvolutionLayer.Builder().kernelSize(<span class="number">5</span>, vectorSize).stride(<span class="number">2</span>, vectorSize)
                                .nOut(cnnLayerFeatureMaps).build(),
                        <span class="string">"input"</span>)
                .addLayer(<span class="string">"cnn6-stride2"</span>,
                        <span class="keyword">new</span> ConvolutionLayer.Builder().kernelSize(<span class="number">6</span>, vectorSize).stride(<span class="number">2</span>, vectorSize)
                                .nOut(cnnLayerFeatureMaps).build(),
                        <span class="string">"input"</span>)
                .addVertex(<span class="string">"merge1"</span>, <span class="keyword">new</span> MergeVertex(), <span class="string">"cnn3"</span>, <span class="string">"cnn4"</span>, <span class="string">"cnn5"</span>, <span class="string">"cnn6"</span>)
                .addLayer(<span class="string">"globalPool1"</span>, <span class="keyword">new</span> GlobalPoolingLayer.Builder().poolingType(globalPoolingType).build(),
                        <span class="string">"merge1"</span>)
                .addVertex(<span class="string">"merge2"</span>, <span class="keyword">new</span> MergeVertex(), <span class="string">"cnn3-stride2"</span>, <span class="string">"cnn4-stride2"</span>, <span class="string">"cnn5-stride2"</span>, <span class="string">"cnn6-stride2"</span>)
                .addLayer(<span class="string">"globalPool2"</span>, <span class="keyword">new</span> GlobalPoolingLayer.Builder().poolingType(globalPoolingType).build(),
                        <span class="string">"merge2"</span>)
                .addLayer(<span class="string">"fc"</span>,
                        <span class="keyword">new</span> DenseLayer.Builder().nOut(<span class="number">200</span>).dropOut(<span class="number">0.5</span>).activation(Activation.LEAKYRELU).build(),
                        <span class="string">"globalPool1"</span>, <span class="string">"globalPool2"</span>)
                .addLayer(<span class="string">"out"</span>,
                        <span class="keyword">new</span> OutputLayer.Builder().lossFunction(LossFunctions.LossFunction.MCXENT)
                                .activation(Activation.SOFTMAX).nOut(<span class="number">15</span>).build(),
                        <span class="string">"fc"</span>)
                .setOutputs(<span class="string">"out"</span>).setInputTypes(InputType.convolutional(truncateReviewsToLength, vectorSize, <span class="number">1</span>))
                .build();

        ComputationGraph net = <span class="keyword">new</span> ComputationGraph(config);
        net.init();
        System.out.println(net.summary());
        Word2Vec word2Vec = WordVectorSerializer.readWord2VecModel(<span class="string">"/toutiao_cat_data/toutiao.vec"</span>);
        System.out.println(<span class="string">"Loading word vectors and creating DataSetIterators"</span>);
        DataSetIterator trainIter = getDataSetIterator(word2Vec, batchSize, truncateReviewsToLength, trainLabelList,
                trainSentences, rng);
        DataSetIterator testIter = getDataSetIterator(word2Vec, batchSize, truncateReviewsToLength, testLabelList,
                testSentences, rng);

        UIServer uiServer = UIServer.getInstance();
        StatsStorage statsStorage = <span class="keyword">new</span> InMemoryStatsStorage();
        uiServer.attach(statsStorage);
        net.setListeners(<span class="keyword">new</span> ScoreIterationListener(<span class="number">100</span>), <span class="keyword">new</span> StatsListener(statsStorage, <span class="number">20</span>),
                <span class="keyword">new</span> EvaluativeListener(testIter, <span class="number">1</span>, InvocationType.EPOCH_END));

        <span class="comment">// net.setListeners(new ScoreIterationListener(100),</span>
        <span class="comment">// new EvaluativeListener(testIter, 1, InvocationType.EPOCH_END));</span>
        net.fit(trainIter, nEpochs);
    &#125;

    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> DataSetIterator <span class="title">getDataSetIterator</span><span class="params">(WordVectors wordVectors, <span class="keyword">int</span> minibatchSize, <span class="keyword">int</span> maxSentenceLength,</span></span>
<span class="function"><span class="params">            List&lt;String&gt; lableList, List&lt;String&gt; sentences, Random rng)</span> </span>&#123;

        LabeledSentenceProvider sentenceProvider = <span class="keyword">new</span> CollectionLabeledSentenceProvider(sentences, lableList, rng);

        <span class="keyword">return</span> <span class="keyword">new</span> CnnSentenceDataSetIterator.Builder().sentenceProvider(sentenceProvider).wordVectors(wordVectors)
                .minibatchSize(minibatchSize).maxSentenceLength(maxSentenceLength).useNormalizedWordVectors(<span class="keyword">false</span>)
                .build();
    &#125;
&#125;

</code></pre><p>代码说明：<br>1、代码分两部分，第一部分是数据预处理，分出20%测试集、80%作为训练集<br>2、第二部分为网络的基本结构代码<br>网络参数详细如下：</p><pre><code class="java">  ===============================================================================================================================================
VertexName (VertexType)            nIn,nOut   TotalParams   ParamsShape                Vertex Inputs                                           
===============================================================================================================================================
input (InputVertex)                -,-        -             -                          -                                                       
cnn3 (ConvolutionLayer)            <span class="number">1</span>,<span class="number">50</span>       <span class="number">15050</span>         W:&#123;<span class="number">50</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">100</span>&#125;, b:&#123;<span class="number">1</span>,<span class="number">50</span>&#125;   [input]                                                 
cnn4 (ConvolutionLayer)            <span class="number">1</span>,<span class="number">50</span>       <span class="number">20050</span>         W:&#123;<span class="number">50</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">100</span>&#125;, b:&#123;<span class="number">1</span>,<span class="number">50</span>&#125;   [input]                                                 
cnn5 (ConvolutionLayer)            <span class="number">1</span>,<span class="number">50</span>       <span class="number">25050</span>         W:&#123;<span class="number">50</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">100</span>&#125;, b:&#123;<span class="number">1</span>,<span class="number">50</span>&#125;   [input]                                                 
cnn6 (ConvolutionLayer)            <span class="number">1</span>,<span class="number">50</span>       <span class="number">30050</span>         W:&#123;<span class="number">50</span>,<span class="number">1</span>,<span class="number">6</span>,<span class="number">100</span>&#125;, b:&#123;<span class="number">1</span>,<span class="number">50</span>&#125;   [input]                                                 
cnn3-stride2 (ConvolutionLayer)    <span class="number">1</span>,<span class="number">50</span>       <span class="number">15050</span>         W:&#123;<span class="number">50</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">100</span>&#125;, b:&#123;<span class="number">1</span>,<span class="number">50</span>&#125;   [input]                                                 
cnn4-stride2 (ConvolutionLayer)    <span class="number">1</span>,<span class="number">50</span>       <span class="number">20050</span>         W:&#123;<span class="number">50</span>,<span class="number">1</span>,<span class="number">4</span>,<span class="number">100</span>&#125;, b:&#123;<span class="number">1</span>,<span class="number">50</span>&#125;   [input]                                                 
cnn5-stride2 (ConvolutionLayer)    <span class="number">1</span>,<span class="number">50</span>       <span class="number">25050</span>         W:&#123;<span class="number">50</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">100</span>&#125;, b:&#123;<span class="number">1</span>,<span class="number">50</span>&#125;   [input]                                                 
cnn6-stride2 (ConvolutionLayer)    <span class="number">1</span>,<span class="number">50</span>       <span class="number">30050</span>         W:&#123;<span class="number">50</span>,<span class="number">1</span>,<span class="number">6</span>,<span class="number">100</span>&#125;, b:&#123;<span class="number">1</span>,<span class="number">50</span>&#125;   [input]                                                 
merge1 (MergeVertex)               -,-        -             -                          [cnn3, cnn4, cnn5, cnn6]                                
merge2 (MergeVertex)               -,-        -             -                          [cnn3-stride2, cnn4-stride2, cnn5-stride2, cnn6-stride2]
globalPool1 (GlobalPoolingLayer)   -,-        <span class="number">0</span>             -                          [merge1]                                                
globalPool2 (GlobalPoolingLayer)   -,-        <span class="number">0</span>             -                          [merge2]                                                
fc-merge (MergeVertex)             -,-        -             -                          [globalPool1, globalPool2]                              
fc (DenseLayer)                    <span class="number">400</span>,<span class="number">200</span>    <span class="number">80200</span>         W:&#123;<span class="number">400</span>,<span class="number">200</span>&#125;, b:&#123;<span class="number">1</span>,<span class="number">200</span>&#125;     [fc-merge]                                              
out (OutputLayer)                  <span class="number">200</span>,<span class="number">15</span>     <span class="number">3015</span>          W:&#123;<span class="number">200</span>,<span class="number">15</span>&#125;, b:&#123;<span class="number">1</span>,<span class="number">15</span>&#125;       [fc]                                                    
-----------------------------------------------------------------------------------------------------------------------------------------------
            Total Parameters:  <span class="number">263615</span>
        Trainable Parameters:  <span class="number">263615</span>
           Frozen Parameters:  <span class="number">0</span>
===============================================================================================================================================

</code></pre><p>DL4J的UIServer界面如下，这里我给定的端口号为9001，打开web界面可以看到平均loss的详情，梯度更新的详情等<br><a target="_blank" rel="external nofollow noopener noreferrer" href="http://localhost:9001/train/overview">http://localhost:9001/train/overview</a><br><img src="https://oscimg.oschina.net/oscnet/c943ed94cdf1c2572c9a16245ff8b781d60.jpg" alt="Test" title="DL4J之CNN对今日头条文本分类"><br>七、掩模<br>句子有长有短，CNN将如何处理呢？<br>处理的办法其实很暴力，将一个minibatch中的最长句子找到，new出最大长度的张量，多余值用掩模掩掉即可，废话不多说，直接上代码</p><pre><code class="java"> <span class="keyword">if</span>(sentencesAlongHeight)&#123;
    featuresMask = Nd4j.create(currMinibatchSize, <span class="number">1</span>, maxLength, <span class="number">1</span>);
    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; currMinibatchSize; i++) &#123;
        <span class="keyword">int</span> sentenceLength = tokenizedSentences.get(i).getFirst().size();
        <span class="keyword">if</span> (sentenceLength &gt;= maxLength) &#123;
            featuresMask.slice(i).assign(<span class="number">1.0</span>);
        &#125; <span class="keyword">else</span> &#123;
            featuresMask.get(NDArrayIndex.point(i), NDArrayIndex.point(<span class="number">0</span>), NDArrayIndex.interval(<span class="number">0</span>, sentenceLength), NDArrayIndex.point(<span class="number">0</span>)).assign(<span class="number">1.0</span>);
        &#125;
    &#125;
&#125; <span class="keyword">else</span> &#123;
    featuresMask = Nd4j.create(currMinibatchSize, <span class="number">1</span>, <span class="number">1</span>, maxLength);
    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; currMinibatchSize; i++) &#123;
        <span class="keyword">int</span> sentenceLength = tokenizedSentences.get(i).getFirst().size();
        <span class="keyword">if</span> (sentenceLength &gt;= maxLength) &#123;
            featuresMask.slice(i).assign(<span class="number">1.0</span>);
        &#125; <span class="keyword">else</span> &#123;
            featuresMask.get(NDArrayIndex.point(i), NDArrayIndex.point(<span class="number">0</span>), NDArrayIndex.point(<span class="number">0</span>), NDArrayIndex.interval(<span class="number">0</span>, sentenceLength)).assign(<span class="number">1.0</span>);
        &#125;
    &#125;
&#125;
</code></pre><pre><code>这里为什么有个if呢？生成句子张量的时候，可以任意指定句子的方向，可以沿着矩阵中height的方向，也可以是width的方向，方向不同，填掩模的那一维也就不同。 
</code></pre><p>八、结果<br>运行了10个Epoch结果如下：</p><pre><code class="java">  ========================Evaluation Metrics========================
 # of classes:    15
 Accuracy:        <span class="number">0.8420</span>
 Precision:       <span class="number">0.8362</span>    (<span class="number">1</span> <span class="class"><span class="keyword">class</span> <span class="title">excluded</span> <span class="title">from</span> <span class="title">average</span>)</span>
 Recall:          0.7783
 F1 Score:        <span class="number">0.8346</span>    (<span class="number">1</span> <span class="class"><span class="keyword">class</span> <span class="title">excluded</span> <span class="title">from</span> <span class="title">average</span>)</span>
Precision, recall &amp; F1: macro-averaged (equally weighted avg. of 15 classes)

Warning: <span class="number">1</span> <span class="class"><span class="keyword">class</span> <span class="title">was</span> <span class="title">never</span> <span class="title">predicted</span> <span class="title">by</span> <span class="title">the</span> <span class="title">model</span> <span class="title">and</span> <span class="title">was</span> <span class="title">excluded</span> <span class="title">from</span> <span class="title">average</span> <span class="title">precision</span></span>
Classes excluded from average precision: [12]

=========================Confusion Matrix=========================
    <span class="number">0</span>    <span class="number">1</span>    <span class="number">2</span>    <span class="number">3</span>    <span class="number">4</span>    <span class="number">5</span>    <span class="number">6</span>    <span class="number">7</span>    <span class="number">8</span>    <span class="number">9</span>   <span class="number">10</span>   <span class="number">11</span>   <span class="number">12</span>   <span class="number">13</span>   <span class="number">14</span>
----------------------------------------------------------------------------
  <span class="number">973</span>   <span class="number">35</span>  <span class="number">114</span>    <span class="number">2</span>    <span class="number">9</span>    <span class="number">8</span>   <span class="number">11</span>   <span class="number">19</span>   <span class="number">14</span>    <span class="number">6</span>   <span class="number">19</span>   <span class="number">11</span>    <span class="number">0</span>   <span class="number">22</span>   <span class="number">13</span> | <span class="number">0</span> = <span class="number">0</span>
   <span class="number">17</span> <span class="number">4636</span>  <span class="number">250</span>   <span class="number">37</span>   <span class="number">51</span>   <span class="number">16</span>   <span class="number">14</span>  <span class="number">151</span>   <span class="number">47</span>   <span class="number">29</span>  <span class="number">232</span>   <span class="number">36</span>    <span class="number">0</span>   <span class="number">82</span>   <span class="number">44</span> | <span class="number">1</span> = <span class="number">1</span>
  <span class="number">103</span>  <span class="number">176</span> <span class="number">6980</span>  <span class="number">108</span>   <span class="number">16</span>    <span class="number">8</span>   <span class="number">31</span>   <span class="number">62</span>   <span class="number">83</span>   <span class="number">41</span>   <span class="number">53</span>   <span class="number">77</span>    <span class="number">0</span>   <span class="number">36</span>  <span class="number">163</span> | <span class="number">2</span> = <span class="number">2</span>
    <span class="number">9</span>   <span class="number">78</span>  <span class="number">244</span> <span class="number">6692</span>   <span class="number">37</span>    <span class="number">9</span>   <span class="number">52</span>   <span class="number">59</span>   <span class="number">33</span>   <span class="number">27</span>   <span class="number">57</span>   <span class="number">54</span>    <span class="number">0</span>   <span class="number">10</span>   <span class="number">96</span> | <span class="number">3</span> = <span class="number">3</span>
    <span class="number">7</span>   <span class="number">52</span>   <span class="number">36</span>   <span class="number">31</span> <span class="number">4072</span>   <span class="number">96</span>  <span class="number">101</span>  <span class="number">107</span>  <span class="number">581</span>   <span class="number">20</span>   <span class="number">64</span>  <span class="number">108</span>    <span class="number">0</span>  <span class="number">135</span>   <span class="number">37</span> | <span class="number">4</span> = <span class="number">4</span>
   <span class="number">12</span>   <span class="number">18</span>   <span class="number">22</span>    <span class="number">8</span>  <span class="number">150</span> <span class="number">3061</span>   <span class="number">27</span>   <span class="number">36</span>   <span class="number">53</span>    <span class="number">2</span>  <span class="number">100</span>   <span class="number">16</span>    <span class="number">0</span>   <span class="number">56</span>    <span class="number">2</span> | <span class="number">5</span> = <span class="number">5</span>
   <span class="number">17</span>   <span class="number">38</span>   <span class="number">71</span>   <span class="number">26</span>   <span class="number">94</span>   <span class="number">13</span> <span class="number">6443</span>   <span class="number">43</span>  <span class="number">174</span>   <span class="number">31</span>  <span class="number">121</span>   <span class="number">39</span>    <span class="number">0</span>   <span class="number">32</span>   <span class="number">34</span> | <span class="number">6</span> = <span class="number">6</span>
   <span class="number">17</span>  <span class="number">157</span>   <span class="number">93</span>   <span class="number">49</span>   <span class="number">62</span>   <span class="number">20</span>   <span class="number">34</span> <span class="number">4793</span>   <span class="number">85</span>   <span class="number">14</span>   <span class="number">58</span>   <span class="number">36</span>    <span class="number">0</span>   <span class="number">49</span>   <span class="number">31</span> | <span class="number">7</span> = <span class="number">7</span>
    <span class="number">1</span>   <span class="number">45</span>   <span class="number">71</span>   <span class="number">21</span>  <span class="number">436</span>   <span class="number">30</span>  <span class="number">195</span>  <span class="number">138</span> <span class="number">7018</span>   <span class="number">48</span>   <span class="number">54</span>   <span class="number">49</span>    <span class="number">0</span>   <span class="number">45</span>  <span class="number">148</span> | <span class="number">8</span> = <span class="number">8</span>
   <span class="number">24</span>   <span class="number">74</span>   <span class="number">84</span>   <span class="number">47</span>   <span class="number">24</span>    <span class="number">1</span>   <span class="number">57</span>   <span class="number">50</span>   <span class="number">68</span> <span class="number">3963</span>   <span class="number">45</span>  <span class="number">431</span>    <span class="number">0</span>    <span class="number">9</span>   <span class="number">65</span> | <span class="number">9</span> = <span class="number">9</span>
    <span class="number">9</span>  <span class="number">165</span>   <span class="number">90</span>   <span class="number">21</span>   <span class="number">40</span>   <span class="number">37</span>   <span class="number">61</span>   <span class="number">40</span>   <span class="number">42</span>   <span class="number">21</span> <span class="number">3428</span>  <span class="number">111</span>    <span class="number">0</span>   <span class="number">78</span>   <span class="number">30</span> | <span class="number">10</span> = <span class="number">10</span>
   <span class="number">47</span>   <span class="number">78</span>  <span class="number">173</span>   <span class="number">52</span>  <span class="number">114</span>   <span class="number">20</span>   <span class="number">48</span>   <span class="number">67</span>   <span class="number">93</span>  <span class="number">320</span>  <span class="number">140</span> <span class="number">4097</span>    <span class="number">0</span>   <span class="number">48</span>   <span class="number">29</span> | <span class="number">11</span> = <span class="number">11</span>
    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>   <span class="number">60</span>    <span class="number">0</span>    <span class="number">1</span>    <span class="number">0</span>    <span class="number">5</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span>    <span class="number">0</span> | <span class="number">12</span> = <span class="number">12</span>
   <span class="number">35</span>  <span class="number">105</span>   <span class="number">31</span>    <span class="number">6</span>  <span class="number">139</span>   <span class="number">37</span>   <span class="number">34</span>   <span class="number">61</span>   <span class="number">79</span>   <span class="number">11</span>  <span class="number">153</span>   <span class="number">35</span>    <span class="number">0</span> <span class="number">3187</span>   <span class="number">12</span> | <span class="number">13</span> = <span class="number">13</span>
   <span class="number">14</span>   <span class="number">36</span>  <span class="number">210</span>  <span class="number">128</span>   <span class="number">31</span>    <span class="number">2</span>   <span class="number">19</span>   <span class="number">20</span>  <span class="number">164</span>   <span class="number">44</span>   <span class="number">38</span>   <span class="number">15</span>    <span class="number">0</span>   <span class="number">19</span> <span class="number">5183</span> | <span class="number">14</span> = <span class="number">14</span>
</code></pre><pre><code>平均准确率0.8420，比原资源中给定的结果略好，F1 score要略差一点，混淆矩阵中，有一个类别，无法被预测到，是因为样本中改类别数据量本身很少，难以抓到共性特征。这里参数如果精心调节一番，迭代更多次数，理论上会有更好的表现。 
</code></pre><p>九、后记<br>读Deeplearning4j是一种享受，优雅的架构，清晰的逻辑，多种设计模式，扩展性强，将有后续博客，对dl4j源码进行剖析。</p><p>快乐源于分享。<br>此博客乃作者原创， 转载请注明出处</p><div class="post-copyright"><div class="content"><p>本文标题： 推荐系列-DL4J之CNN对今日头条文本分类</p><p>本文作者： OSChina</p><p>发布时间： 2021年04月15日 09:19</p><p>最后更新： 2022年03月27日 09:29</p><p>原始链接： <a class="post-url" href="/a0ca7576/" title="推荐系列-DL4J之CNN对今日头条文本分类">https://www.hosiang.cn/a0ca7576/</a></p><p>版权声明： 本文著作权归作者所有，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noopener noreferrer" target="_blank">CC BY-NC-SA 4.0</a>许可协议，转载请注明出处！</p><footer><a href="https://www.hosiang.cn"><img src="/../images/logo.png" alt="Howe Hsiang"> Howe Hsiang</a></footer></div></div><div class="page-reward"><a id="rewardBtn" href="javascript:;">赏</a></div><div id="reward" class="post-modal reward-lay"><a class="close" href="javascript:;" id="reward-close">×</a> <span class="reward-title"><i class="icon icon-quote-left"></i> 喜欢就赞赏一下呗！ <i class="icon icon-quote-right"></i></span><div class="reward-content"><div class="reward-code"><img id="rewardCode" src="/images/threepay_code.jpg" alt="打赏二维码"></div><div class="reward-select"></div></div></div></div><footer class="article-footer"><div class="post-share"><a href="javascript:" id="share-sub" class="post-share-fab"><i class="fa fa-share-alt" style="padding-top:11px!important"></i></a><div class="post-share-list" id="share-list"><ul class="share-icons"><li><a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://www.hosiang.cn/a0ca7576/" data-title="Facebook" rel="external nofollow noopener noreferrer"><i class="fa fa-facebook" style="padding-top:9px!important"></i></a></li><li><a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《推荐系列-DL4J之CNN对今日头条文本分类》 — 狂欢马克思&url=https://www.hosiang.cn/a0ca7576/&via=https://www.hosiang.cn" data-title="Twitter" rel="external nofollow noopener noreferrer"><i class="fa fa-twitter" style="padding-top:9px!important"></i></a></li><li><a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://www.hosiang.cn/a0ca7576/" data-title="Google+" rel="external nofollow noopener noreferrer"><i class="fa fa-google-plus" style="padding-top:9px!important"></i></a></li><li><a class="qq share-sns" target="_blank" href="https://connect.qq.com/widget/shareqq/index.html?url=https://www.hosiang.cn/a0ca7576/&title=《推荐系列-DL4J之CNN对今日头条文本分类》 — 狂欢马克思&source=&emsp;&emsp;一、数据集介绍 数据来源：今日头条客户端 数据格式如下： 6551700932705387022_!101!_news_cultu..." data-title="QQ" rel="external nofollow noopener noreferrer"><i class="fa fa-qq" style="padding-top:9px!important"></i></a></li><li><a class="weixin share-sns" id="wxFab" href="javascript:" data-title="微信"><i class="fa fa-weixin" style="padding-top:9px!important"></i></a></li><li><a class="weibo share-sns" target="_blank" href="https://service.weibo.com/share/share.php?url=https://www.hosiang.cn/a0ca7576/&title=《推荐系列-DL4J之CNN对今日头条文本分类》 — 狂欢马克思&pic=https://static.oschina.net/uploads/img/201909/29122119_FTgB.jpg" data-title="微博" rel="external nofollow noopener noreferrer"><i class="fa fa-weibo" style="padding-top:9px!important"></i></a></li></ul></div></div><div class="post-modal wx-share" id="wxShare"><a class="close" href="javascript:" id="wxShare-close">×</a><p>扫一扫，分享到微信</p><img src="//api.qrserver.com/v1/create-qr-code/?data=https://www.hosiang.cn/a0ca7576/" alt="微信分享二维码"></div><div class="mask"></div><ul class="article-footer-menu"><li class="article-footer-tags"><i class="fa fa-tags"></i> <a href="/tags/Popular/" class="color3">Popular</a></li></ul></footer></div></article><nav id="article-nav"><a href="/a21b8c79/" id="article-nav-newer" class="article-nav-link-wrap"><span class="article-nav-title"><i class="fa fa-hand-o-left" aria-hidden="true"></i> 推荐系列-BaikalDB技术实现内幕（一）-- 分布式事务实现 </span></a><a href="/e6fec711/" id="article-nav-older" class="article-nav-link-wrap"><span class="article-nav-title">推荐系列-Java中的屠龙之术——如何修改语法树</span> <i class="fa fa-hand-o-right" aria-hidden="true"></i></a></nav><div id="gitalk"></div><link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css"><script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script><script>var gitalk=new Gitalk({repo:"bolg-comment",owner:"Hosiang1026",admin:"Hosiang1026",clientID:"37a2dd4473e8970cecc2",clientSecret:"e30efa17d86d9de4f4ab810872dc62a7b2e7e634",pagerDirection:"last",distractionFreeMode:!0,createIssueManually:!1});gitalk.render("gitalk")</script></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner"><script id="_wau78w">var _wau=_wau||[];_wau.push(["small","5dnguv4c2n","78w"])</script><script async src="//waust.at/s.js"></script><p><span id="busuanzi_container_site_uv" style="display:none"><span class="post-count">总字数：<span>1543.2k</span> </span>总访客数：<span id="busuanzi_value_site_uv"></span> </span><span id="busuanzi_container_site_pv" style="display:none">总访问量：<span id="busuanzi_value_site_pv"></span></span><br><span id="TimeShow">本站</span><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span><br>Copyright&copy; 2018 - 2022 狂欢马克思 <a href="https://beian.miit.gov.cn" rel="external nofollow noopener noreferrer" target="_blank">京ICP备17060439号</a></p></div></div><script>var now=new Date;function createtime(){var n=new Date("2017/09/18");now.setTime(now.getTime()+250),days=(now-n)/1e3/60/60/24,dnum=Math.floor(days),hours=(now-n)/1e3/60/60-24*dnum,hnum=Math.floor(hours),1==String(hnum).length&&(hnum="0"+hnum),minutes=(now-n)/1e3/60-1440*dnum-60*hnum,mnum=Math.floor(minutes),1==String(mnum).length&&(mnum="0"+mnum),seconds=(now-n)/1e3-86400*dnum-3600*hnum-60*mnum,snum=Math.round(seconds),1==String(snum).length&&(snum="0"+snum),document.getElementById("timeDate").innerHTML="安全运行 "+dnum+" 天 ",document.getElementById("times").innerHTML=hnum+" 小时 "+mnum+" 分 "+snum+" 秒"}setInterval("createtime()",800)</script></footer><script>var mihoConfig={root:"https://www.hosiang.cn",animate:"true",isHome:"false",share:"true",reward:" 1"}</script><div class="sidebar"><div id="sidebar-search" title="Search"><i class="fa fa-search"></i></div><div id="sidebar-category" title="Categories"><i class="fa fa-book"></i></div><div id="sidebar-tag" title="Tags"><i class="fa fa-tags"></i></div><div id="sidebar-top"><span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span></div></div><div class="sidebar-menu-box" id="sidebar-menu-box"><div class="sidebar-menu-box-container"><div id="sidebar-menu-box-categories"><a class="category-link" href="/categories/%E5%85%B4%E8%B6%A3%E7%88%B1%E5%A5%BD/">兴趣爱好</a><a class="category-link" href="/categories/%E5%85%B6%E4%BB%96%E5%BC%80%E5%8F%91/">其他开发</a><a class="category-link" href="/categories/%E5%89%8D%E6%B2%BF%E5%BC%80%E5%8F%91/">前沿开发</a><a class="category-link" href="/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/">前端开发</a><a class="category-link" href="/categories/%E5%8D%87%E7%BA%A7%E7%89%88%E6%9C%AC/">升级版本</a><a class="category-link" href="/categories/%E5%8D%9A%E5%AE%A2%E6%95%99%E7%A8%8B/">博客教程</a><a class="category-link" href="/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/">后端开发</a><a class="category-link" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a><a class="category-link" href="/categories/%E6%97%A5%E5%B8%B8%E8%AE%B0%E5%BD%95/">日常记录</a><a class="category-link" href="/categories/%E7%83%AD%E9%97%A8%E6%96%87%E7%AB%A0/">热门文章</a></div><div id="sidebar-menu-box-tags"><a href="/tags/Ajax/" style="font-size:10px">Ajax</a> <a href="/tags/AliGenie/" style="font-size:10px">AliGenie</a> <a href="/tags/Alipay/" style="font-size:10px">Alipay</a> <a href="/tags/Android/" style="font-size:10px">Android</a> <a href="/tags/Blockchain/" style="font-size:16px">Blockchain</a> <a href="/tags/CQRS/" style="font-size:10px">CQRS</a> <a href="/tags/Database/" style="font-size:14px">Database</a> <a href="/tags/Docker/" style="font-size:10px">Docker</a> <a href="/tags/EasyUI/" style="font-size:10px">EasyUI</a> <a href="/tags/Guitar/" style="font-size:10px">Guitar</a> <a href="/tags/Hackintosh/" style="font-size:12px">Hackintosh</a> <a href="/tags/Hexo/" style="font-size:14px">Hexo</a> <a href="/tags/IntelliJ-IDEA/" style="font-size:10px">IntelliJ IDEA</a> <a href="/tags/Interview/" style="font-size:18px">Interview</a> <a href="/tags/Java/" style="font-size:12px">Java</a> <a href="/tags/Kali-Linux/" style="font-size:10px">Kali Linux</a> <a href="/tags/Life/" style="font-size:16px">Life</a> <a href="/tags/Mac-OS/" style="font-size:12px">Mac OS</a> <a href="/tags/MultiThread/" style="font-size:10px">MultiThread</a> <a href="/tags/NodeJS/" style="font-size:10px">NodeJS</a> <a href="/tags/Popular/" style="font-size:20px">Popular</a> <a href="/tags/Python/" style="font-size:10px">Python</a> <a href="/tags/SaaS/" style="font-size:10px">SaaS</a> <a href="/tags/Servlet/" style="font-size:10px">Servlet</a> <a href="/tags/Spring/" style="font-size:16px">Spring</a> <a href="/tags/Upgrade/" style="font-size:10px">Upgrade</a> <a href="/tags/Web/" style="font-size:10px">Web</a> <a href="/tags/Windows/" style="font-size:10px">Windows</a> <a href="/tags/Work/" style="font-size:10px">Work</a> <a href="/tags/iOS/" style="font-size:10px">iOS</a></div></div><a href="javascript:" class="sidebar-menu-box-close">&times;</a></div><div class="mobile-header-menu-nav" id="mobile-header-menu-nav"><div class="mobile-header-menu-container"><span class="title">导航</span><ul class="mobile-header-menu-navbar"><li><a href="/"><i class="fa fa-home"></i><span>主页</span></a></li><li><a href="/archives"><i class="fa fa-archive"></i><span>归档</span></a></li><li><a href="/gitbook"><i class="fa fa-columns"></i><span>笔记</span></a></li><li><a href="/music"><i class="fa fa-music"></i><span>音乐</span></a></li><li><a href="/photo"><i class="fa fa-picture-o"></i><span>相册</span></a></li><li><a href="/collection"><i class="fa fa-envira"></i><span>收藏</span></a></li><li><a href="/about"><i class="fa fa-user"></i><span>关于</span></a></li></ul></div><div class="mobile-header-tag-container"><span class="title">标签</span><div id="mobile-header-container-tags"><a href="/tags/Ajax/" style="font-size:10px">Ajax</a> <a href="/tags/AliGenie/" style="font-size:10px">AliGenie</a> <a href="/tags/Alipay/" style="font-size:10px">Alipay</a> <a href="/tags/Android/" style="font-size:10px">Android</a> <a href="/tags/Blockchain/" style="font-size:16px">Blockchain</a> <a href="/tags/CQRS/" style="font-size:10px">CQRS</a> <a href="/tags/Database/" style="font-size:14px">Database</a> <a href="/tags/Docker/" style="font-size:10px">Docker</a> <a href="/tags/EasyUI/" style="font-size:10px">EasyUI</a> <a href="/tags/Guitar/" style="font-size:10px">Guitar</a> <a href="/tags/Hackintosh/" style="font-size:12px">Hackintosh</a> <a href="/tags/Hexo/" style="font-size:14px">Hexo</a> <a href="/tags/IntelliJ-IDEA/" style="font-size:10px">IntelliJ IDEA</a> <a href="/tags/Interview/" style="font-size:18px">Interview</a> <a href="/tags/Java/" style="font-size:12px">Java</a> <a href="/tags/Kali-Linux/" style="font-size:10px">Kali Linux</a> <a href="/tags/Life/" style="font-size:16px">Life</a> <a href="/tags/Mac-OS/" style="font-size:12px">Mac OS</a> <a href="/tags/MultiThread/" style="font-size:10px">MultiThread</a> <a href="/tags/NodeJS/" style="font-size:10px">NodeJS</a> <a href="/tags/Popular/" style="font-size:20px">Popular</a> <a href="/tags/Python/" style="font-size:10px">Python</a> <a href="/tags/SaaS/" style="font-size:10px">SaaS</a> <a href="/tags/Servlet/" style="font-size:10px">Servlet</a> <a href="/tags/Spring/" style="font-size:16px">Spring</a> <a href="/tags/Upgrade/" style="font-size:10px">Upgrade</a> <a href="/tags/Web/" style="font-size:10px">Web</a> <a href="/tags/Windows/" style="font-size:10px">Windows</a> <a href="/tags/Work/" style="font-size:10px">Work</a> <a href="/tags/iOS/" style="font-size:10px">iOS</a></div></div></div><div class="search-wrap"><span class="search-close">&times;</span> <a href="javascript:" class="header-icon waves-effect waves-circle waves-light" id="back"><i class="icon icon-lg icon-chevron-left"></i> </a><input class="search-field" placeholder="Search..." id="keywords"> <a id="search-submit" href="javascript:"><i class="fa fa-search"></i></a><div class="search-container" id="search-container"><ul class="search-result" id="search-result"></ul></div></div><div id="search-tpl"><li class="search-result-item"><a href="{url}" class="search-item-li"><span class="search-item-li-title" title="{title}">{title}</span></a></li></div><script src="/js/search.js"></script><script src="/js/main.js"></script><script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script><div id="particles"></div><script src="/js/particles.js"></script><link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css"><script src="//cdn.bootcss.com/scrollReveal.js/3.0.5/scrollreveal.js"></script><script src="/js/animate.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{jsonPath:"/live2dw/assets/hijiki.model.json"},display:{position:"right",width:150,height:300},mobile:{show:!0,scale:.5},log:!1})</script></body></html>